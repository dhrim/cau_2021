{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "korean_sentence_relation_regression_with_bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pyz8OyCRKRz8"
      },
      "source": [
        "# Bert를 사용한 문장 간 관계수치 예측\n",
        "\n",
        "2개의 문장 간의 관계를 수치로 에측한다.\n",
        "\n",
        "0 : 무관\n",
        "5 : 상관"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFwbg7k1KZrK"
      },
      "source": [
        "# 필요 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTUt2OoT04Kh",
        "outputId": "a6f4a27a-7b40-44a0-ba05-0fecc7377f63"
      },
      "source": [
        "!pip install transformers==3.0.2\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==3.0.2\n",
            "  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n",
            "\u001b[K     |████████████████████████████████| 769 kB 7.4 MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
            "  Downloading tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 44.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 64.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (21.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 75.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.1.0)\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.46 sentencepiece-0.1.96 tokenizers-0.8.1rc1 transformers-3.0.2\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-FHX9tOK4pV"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import TFBertModel\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex8GjpDqK7Lm"
      },
      "source": [
        "#random seed 고정\n",
        "tf.random.set_seed(1234)\n",
        "np.random.seed(1234)\n",
        "\n",
        "SEQ_LENGTH = 128\n",
        "BERT_MODEL_NAME = 'bert-base-multilingual-cased'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "104nTDhQLQmP"
      },
      "source": [
        "# 데이터"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bobHiFxmBN01"
      },
      "source": [
        "## 데이터 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sVLtmvLPsnC",
        "outputId": "8db7c1ba-a63e-4247-b291-58a08d825b61"
      },
      "source": [
        "!git clone https://github.com/kakaobrain/KorNLUDatasets"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'KorNLUDatasets'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 16 (delta 1), reused 16 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (16/16), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isfRmCyKPset",
        "outputId": "94248407-528f-4a8b-ce15-f76e2fed2183"
      },
      "source": [
        "!wc ./KorNLUDatasets/KorNLI/snli_1.0_train.ko.tsv"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  550153  8595590 78486224 ./KorNLUDatasets/KorNLI/snli_1.0_train.ko.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZu1lTyM28Rf"
      },
      "source": [
        "## 데이터 로딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsyECR_ixL2t"
      },
      "source": [
        "df = pd.read_csv(\"KorNLUDatasets/KorSTS/sts-train.tsv\", delimiter = '\\t', quoting = 3)"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "kVPkn52ZxbU8",
        "outputId": "14bc91fa-b58c-42ef-a7c5-57717eb9b68b"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genre</th>\n",
              "      <th>filename</th>\n",
              "      <th>year</th>\n",
              "      <th>id</th>\n",
              "      <th>score</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>main-news</td>\n",
              "      <td>headlines</td>\n",
              "      <td>2013</td>\n",
              "      <td>237</td>\n",
              "      <td>3.8</td>\n",
              "      <td>프랑스 사회주의 정당이 의회 승리</td>\n",
              "      <td>프랑스 사회주의자들이 절대 의회 다수를 차지하다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>main-news</td>\n",
              "      <td>headlines</td>\n",
              "      <td>2013</td>\n",
              "      <td>477</td>\n",
              "      <td>4.2</td>\n",
              "      <td>남아프리카 경찰은 30명의 광부들을 총으로 쏘았다.</td>\n",
              "      <td>남아프리카 경찰은 그들이 30명 이상의 광부들을 죽였다고 말한다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>main-captions</td>\n",
              "      <td>MSRvid</td>\n",
              "      <td>2012test</td>\n",
              "      <td>582</td>\n",
              "      <td>2.5</td>\n",
              "      <td>남자가 닭고기를 용기에 넣고 있다.</td>\n",
              "      <td>한 남자가 상자에 음식을 넣고 있다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>main-captions</td>\n",
              "      <td>images</td>\n",
              "      <td>2014</td>\n",
              "      <td>21</td>\n",
              "      <td>3.0</td>\n",
              "      <td>노란 꽃 앞에 서 있는 검은 개</td>\n",
              "      <td>들판에 서 있는 검은 개</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>main-forum</td>\n",
              "      <td>deft-forum</td>\n",
              "      <td>2014</td>\n",
              "      <td>373</td>\n",
              "      <td>4.6</td>\n",
              "      <td>세례자 존은 출생시부터 나자라이트였다.</td>\n",
              "      <td>세례 요한은 출생 때부터 나자라이트였다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>main-captions</td>\n",
              "      <td>MSRvid</td>\n",
              "      <td>2012train</td>\n",
              "      <td>665</td>\n",
              "      <td>0.0</td>\n",
              "      <td>동물이 걷고 있다.</td>\n",
              "      <td>한 여성이 눈 화장을 하고 있다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>main-news</td>\n",
              "      <td>headlines</td>\n",
              "      <td>2015</td>\n",
              "      <td>591</td>\n",
              "      <td>4.0</td>\n",
              "      <td>베네수엘라 감옥에서 폭력으로 16명 사망</td>\n",
              "      <td>베네수엘라 감옥에서 16명 사망</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>main-captions</td>\n",
              "      <td>MSRvid</td>\n",
              "      <td>2012test</td>\n",
              "      <td>52</td>\n",
              "      <td>2.4</td>\n",
              "      <td>남자가 빵을 자르고 있다.</td>\n",
              "      <td>남자가 양파를 자르고 있다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>main-captions</td>\n",
              "      <td>MSRvid</td>\n",
              "      <td>2012train</td>\n",
              "      <td>143</td>\n",
              "      <td>5.0</td>\n",
              "      <td>계단을 내려가는 한 남자.</td>\n",
              "      <td>한 남자가 계단을 걸어 내려간다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>main-news</td>\n",
              "      <td>headlines</td>\n",
              "      <td>2014</td>\n",
              "      <td>629</td>\n",
              "      <td>3.8</td>\n",
              "      <td>베네수엘라의 후고 차베스는 암으로 사망한다.</td>\n",
              "      <td>베네수엘라 대통령 휴고 차베스가 58세에 암으로 사망하다.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           genre  ...                             sentence2\n",
              "0      main-news  ...            프랑스 사회주의자들이 절대 의회 다수를 차지하다\n",
              "1      main-news  ...  남아프리카 경찰은 그들이 30명 이상의 광부들을 죽였다고 말한다.\n",
              "2  main-captions  ...                  한 남자가 상자에 음식을 넣고 있다.\n",
              "3  main-captions  ...                         들판에 서 있는 검은 개\n",
              "4     main-forum  ...                세례 요한은 출생 때부터 나자라이트였다.\n",
              "5  main-captions  ...                    한 여성이 눈 화장을 하고 있다.\n",
              "6      main-news  ...                     베네수엘라 감옥에서 16명 사망\n",
              "7  main-captions  ...                       남자가 양파를 자르고 있다.\n",
              "8  main-captions  ...                    한 남자가 계단을 걸어 내려간다.\n",
              "9      main-news  ...      베네수엘라 대통령 휴고 차베스가 58세에 암으로 사망하다.\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Satro0bK25CA"
      },
      "source": [
        "## 데이터 섞기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "Rj4fWpN523i8",
        "outputId": "a8c96d63-f884-490b-a077-474e613ff628"
      },
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True) \n",
        "\n",
        "df.head()"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genre</th>\n",
              "      <th>filename</th>\n",
              "      <th>year</th>\n",
              "      <th>id</th>\n",
              "      <th>score</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>main-news</td>\n",
              "      <td>headlines</td>\n",
              "      <td>2013</td>\n",
              "      <td>237</td>\n",
              "      <td>3.8</td>\n",
              "      <td>프랑스 사회주의 정당이 의회 승리</td>\n",
              "      <td>프랑스 사회주의자들이 절대 의회 다수를 차지하다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>main-news</td>\n",
              "      <td>headlines</td>\n",
              "      <td>2013</td>\n",
              "      <td>477</td>\n",
              "      <td>4.2</td>\n",
              "      <td>남아프리카 경찰은 30명의 광부들을 총으로 쏘았다.</td>\n",
              "      <td>남아프리카 경찰은 그들이 30명 이상의 광부들을 죽였다고 말한다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>main-captions</td>\n",
              "      <td>MSRvid</td>\n",
              "      <td>2012test</td>\n",
              "      <td>582</td>\n",
              "      <td>2.5</td>\n",
              "      <td>남자가 닭고기를 용기에 넣고 있다.</td>\n",
              "      <td>한 남자가 상자에 음식을 넣고 있다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>main-captions</td>\n",
              "      <td>images</td>\n",
              "      <td>2014</td>\n",
              "      <td>21</td>\n",
              "      <td>3.0</td>\n",
              "      <td>노란 꽃 앞에 서 있는 검은 개</td>\n",
              "      <td>들판에 서 있는 검은 개</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>main-forum</td>\n",
              "      <td>deft-forum</td>\n",
              "      <td>2014</td>\n",
              "      <td>373</td>\n",
              "      <td>4.6</td>\n",
              "      <td>세례자 존은 출생시부터 나자라이트였다.</td>\n",
              "      <td>세례 요한은 출생 때부터 나자라이트였다.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           genre  ...                             sentence2\n",
              "0      main-news  ...            프랑스 사회주의자들이 절대 의회 다수를 차지하다\n",
              "1      main-news  ...  남아프리카 경찰은 그들이 30명 이상의 광부들을 죽였다고 말한다.\n",
              "2  main-captions  ...                  한 남자가 상자에 음식을 넣고 있다.\n",
              "3  main-captions  ...                         들판에 서 있는 검은 개\n",
              "4     main-forum  ...                세례 요한은 출생 때부터 나자라이트였다.\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ke8GRyV3AMJ"
      },
      "source": [
        "## 필요 입출력 값 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrebOR3Ixtah"
      },
      "source": [
        "sentences1 = df.sentence1.values.copy().astype(np.str)\n",
        "sentences2 = df.sentence2.values.copy().astype(np.str)\n",
        "labels = df.score.values.copy().astype(np.float)/5.0"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pPRFEcJEfrU",
        "outputId": "4b1a740c-6ca4-496b-c81a-ac4ead11a453"
      },
      "source": [
        "print(sentences1.shape)\n",
        "print(sentences2.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5749,)\n",
            "(5749,)\n",
            "(5749,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KatYM0gqw69n"
      },
      "source": [
        "필요 시, 실습 시간 관계로 전체 중에 일부 만 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2od6yPKw1aC"
      },
      "source": [
        "COUNT = 10000\n",
        "sentences1 = sentences1[:COUNT]\n",
        "sentences2 = sentences2[:COUNT]\n",
        "labels = labels[:COUNT]"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Rvjka1yNJhb"
      },
      "source": [
        "## 토큰나이저 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6_OFM9aLbUg"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME, do_lower_case=False, model_max_length=SEQ_LENGTH)"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1BOJT-vLbRo",
        "outputId": "e085b962-f570-4f80-ad6f-0e755d651717"
      },
      "source": [
        "encoded_tokens= tokenizer.encode(\"하늘이 푸르다.\", text_pair=\"파란색이 좋아.\")\n",
        "print(encoded_tokens)\n",
        "print(tokenizer.convert_ids_to_tokens(encoded_tokens))"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 9952, 118762, 10739, 9935, 31401, 11903, 119, 102, 9901, 49919, 41442, 10739, 9685, 16985, 119, 102]\n",
            "['[CLS]', '하', '##늘', '##이', '푸', '##르', '##다', '.', '[SEP]', '파', '##란', '##색', '##이', '좋', '##아', '.', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9mDZ9ihLbMQ",
        "outputId": "2c8d969c-b301-43ad-877f-052bc5852e6b"
      },
      "source": [
        "tokenized = tokenizer(\"하늘이 푸르다.\", text_pair=\"파란색이 좋아.\", max_length=20, padding='max_length')\n",
        "print(tokenizer.decode(tokenized['input_ids']))\n",
        "print(tokenizer.convert_ids_to_tokens(tokenized['input_ids']))\n",
        "print(tokenized['input_ids'])\n",
        "print(tokenized['attention_mask'])\n",
        "print(tokenized['token_type_ids'])"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] 하늘이 푸르다. [SEP] 파란색이 좋아. [SEP] [PAD] [PAD] [PAD]\n",
            "['[CLS]', '하', '##늘', '##이', '푸', '##르', '##다', '.', '[SEP]', '파', '##란', '##색', '##이', '좋', '##아', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]']\n",
            "[101, 9952, 118762, 10739, 9935, 31401, 11903, 119, 102, 9901, 49919, 41442, 10739, 9685, 16985, 119, 102, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEnAfwf_Vb1I"
      },
      "source": [
        "## x, y 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4SlXQh2LwfI"
      },
      "source": [
        "\n",
        "tokernizer 사용 중에 경고 메시지가 많이 뜬다. 억제한다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twrpGcuELwfS"
      },
      "source": [
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7I3pUuBq7Ak"
      },
      "source": [
        "def build_model_input(sentences1, sentences2):\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  token_type_ids = []\n",
        "\n",
        "  for sentence1, sentence2 in zip(sentences1, sentences2):\n",
        "    tokenized = tokenizer(sentence1, text_pair=sentence2, max_length=SEQ_LENGTH, padding='max_length')\n",
        "    # tokenized = {'input_ids': [101, ...], 'token_type_ids': [0, ...], 'attention_mask': [1, ...]}\n",
        "    input_ids.append(tokenized['input_ids'][:SEQ_LENGTH]) # 버그인지 몰라도 SEQ_LENGTH이상이어도 더 크게 나온다.\n",
        "    attention_masks.append(tokenized['attention_mask'][:SEQ_LENGTH])\n",
        "    token_type_ids.append(tokenized['token_type_ids'][:SEQ_LENGTH])\n",
        "\n",
        "  return (np.array(input_ids), np.array(attention_masks), np.array(token_type_ids))\n"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHtYY3r8LbJV"
      },
      "source": [
        "x = build_model_input(sentences1, sentences2)\n",
        "y = labels"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeELyXfvidtQ",
        "outputId": "64edbb2e-11b5-4b52-b545-9f70eb7f431f"
      },
      "source": [
        "print(x[0].shape)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5749, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HfIzDjeY0d7"
      },
      "source": [
        "## train/test 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxqohOmDa72g"
      },
      "source": [
        "def split_bert_data(x, y, test_ratio):\n",
        "  split_index = int(len(y)*(1-test_ratio))\n",
        "  train_x = (x[0][:split_index], x[1][:split_index], x[2][:split_index])\n",
        "  test_x  = (x[0][split_index:], x[1][split_index:], x[2][split_index:])\n",
        "  train_y, test_y = y[:split_index], y[split_index:]\n",
        "\n",
        "  return (train_x, train_y), (test_x, test_y)\n",
        "\n",
        "(train_x, train_y), (test_x, test_y) = split_bert_data(x, y, test_ratio=0.2)"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWb-Ip8pYEQg"
      },
      "source": [
        "# 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Txqhf6XYFyP"
      },
      "source": [
        "## 모델 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-vXh3QmT5nu"
      },
      "source": [
        "from tensorflow.keras.initializers import TruncatedNormal\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "class TFBertPredictor(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(TFBertPredictor, self).__init__()\n",
        "\n",
        "    self.bert = TFBertModel.from_pretrained(BERT_MODEL_NAME)\n",
        "    self.dropout = Dropout(self.bert.config.hidden_dropout_prob)\n",
        "    self.predcitor = Dense(1, kernel_initializer=TruncatedNormal(self.bert.config.initializer_range))\n",
        "\n",
        "  def call(self, inputs, attention_mask=None, token_type_ids=None, training=True):\n",
        "\n",
        "    outputs = self.bert(inputs, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "    # outputs 값: # sequence_output, pooled_output, (hidden_states), (attentions)\n",
        "    pooled_output = outputs[1] \n",
        "    v = self.dropout(pooled_output, training=training)\n",
        "    out = self.predcitor(v)\n",
        "\n",
        "    return out\n",
        "\n",
        "model = TFBertPredictor()\n"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfycyrGDYg51"
      },
      "source": [
        "참고로 Bert의 default 설정은 다음과 같다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rFMC5hjYe93",
        "outputId": "5d4caaff-a44a-411b-ab02-1b9eb18c51f1"
      },
      "source": [
        "print(model.bert.config)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZIUqxuBbfq4"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "optimizer = Adam(3e-5)\n",
        "loss = SparseCategoricalCrossentropy()\n",
        "model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\"])\n"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5JdxQn-bNPp"
      },
      "source": [
        "## 학습 실행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WU1NbHObNBY",
        "outputId": "d4231fa8-203b-4d03-cb49-62a0db4c74eb"
      },
      "source": [
        "history = model.fit(train_x, train_y, epochs=5, batch_size=32, validation_split=0.1)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "130/130 [==============================] - 123s 518ms/step - loss: 0.0557 - mae: 0.1864 - val_loss: 0.0368 - val_mae: 0.1500\n",
            "Epoch 2/5\n",
            "130/130 [==============================] - 65s 497ms/step - loss: 0.0354 - mae: 0.1485 - val_loss: 0.0288 - val_mae: 0.1312\n",
            "Epoch 3/5\n",
            "130/130 [==============================] - 65s 497ms/step - loss: 0.0258 - mae: 0.1271 - val_loss: 0.0356 - val_mae: 0.1491\n",
            "Epoch 4/5\n",
            "130/130 [==============================] - 65s 497ms/step - loss: 0.0194 - mae: 0.1093 - val_loss: 0.0316 - val_mae: 0.1356\n",
            "Epoch 5/5\n",
            "130/130 [==============================] - 65s 498ms/step - loss: 0.0156 - mae: 0.0988 - val_loss: 0.0308 - val_mae: 0.1330\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JlJLgKw0iHT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b0a326b-a3b2-4918-acb0-98d33ff07e71"
      },
      "source": [
        "loss, mape = model.evaluate(test_x, test_y, batch_size=32)\n",
        "print(\"loss =\", loss)\n",
        "print(\"mape =\", mape)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 [==============================] - 6s 163ms/step - loss: 0.0304 - mae: 0.1318\n",
            "loss = 0.030417706817388535\n",
            "mape = 0.13178132474422455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvnNncG_3p87"
      },
      "source": [
        "## 예측 실행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNsQMfcjV5T8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad1493bd-d55f-4b64-afd1-78eba288e806"
      },
      "source": [
        "def do_classify(sentence1, sentence2):\n",
        "  model_input = build_model_input([sentence1], [sentence2])\n",
        "  y_ = model.predict(model_input)\n",
        "  print(sentence1, sentence2, \"-->\", \"score :\",y_[0])\n",
        "\n",
        "do_classify(\"나는 왜 그런지 잘 모르겠다.\", \"하늘이 푸르다.\")\n",
        "do_classify(\"나는 왜 그런지 잘 모르겠다.\", \"나는 왜 그런 일이 일어났는지 모르겠어.\")\n",
        "do_classify(\"나는 왜 그런지 잘 모르겠다.\", \"나는 왜 그런지 완전히 모르겠어.\")"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "나는 왜 그런지 잘 모르겠다. 하늘이 푸르다. --> score : [0.10910998]\n",
            "나는 왜 그런지 잘 모르겠다. 나는 왜 그런 일이 일어났는지 모르겠어. --> score : [0.5142913]\n",
            "나는 왜 그런지 잘 모르겠다. 나는 왜 그런지 완전히 모르겠어. --> score : [0.6512094]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovKfa2IBZ-SZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}