{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "korean_word_sequence_classification_with_bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pyz8OyCRKRz8"
      },
      "source": [
        "# Bert를 사용한 한글 단어열 분류"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBC-mz4q4kIr"
      },
      "source": [
        "copy from https://github.com/NLP-kr/tensorflow-ml-nlp-tf2/blob/master/7.PRETRAIN_METHOD/7.2.1.bert_finetune_NSMC.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFwbg7k1KZrK"
      },
      "source": [
        "# 필요 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTUt2OoT04Kh",
        "outputId": "09b5a3a2-6bb7-4265-f537-f6709ec2ed63"
      },
      "source": [
        "!pip install transformers==3.0.2\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==3.0.2\n",
            "  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n",
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 31.5 MB/s eta 0:00:01\r\u001b[K     |▉                               | 20 kB 19.3 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30 kB 16.2 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 71 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████                          | 143 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████                        | 194 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 769 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.3.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 62.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (21.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 57.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.19.5)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "  Downloading tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 53.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.46 sentencepiece-0.1.96 tokenizers-0.8.1rc1 transformers-3.0.2\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-FHX9tOK4pV"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import TFBertModel\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex8GjpDqK7Lm"
      },
      "source": [
        "#random seed 고정\n",
        "tf.random.set_seed(1234)\n",
        "np.random.seed(1234)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "SEQ_LENGTH = 128\n",
        "\n",
        "CACHE_DIR = 'bert_ckpt'\n",
        "\n",
        "BERT_MODEL_NAME = 'bert-base-multilingual-cased'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "104nTDhQLQmP"
      },
      "source": [
        "# 데이터"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bobHiFxmBN01"
      },
      "source": [
        "## 데이터 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-pgao0HxEbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e7df432-579a-4ec3-85ed-14bb75725f6c"
      },
      "source": [
        "!wget https://github.com/dhrim/deep_learning_data/raw/master/movie_ratings.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-16 22:42:27--  https://github.com/dhrim/deep_learning_data/raw/master/movie_ratings.txt\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/dhrim/deep_learning_data/master/movie_ratings.txt [following]\n",
            "--2021-11-16 22:42:27--  https://raw.githubusercontent.com/dhrim/deep_learning_data/master/movie_ratings.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19515078 (19M) [text/plain]\n",
            "Saving to: ‘movie_ratings.txt’\n",
            "\n",
            "movie_ratings.txt   100%[===================>]  18.61M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-11-16 22:42:29 (152 MB/s) - ‘movie_ratings.txt’ saved [19515078/19515078]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZu1lTyM28Rf"
      },
      "source": [
        "## 데이터 로딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsyECR_ixL2t"
      },
      "source": [
        "df = pd.read_table(\"movie_ratings.txt\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "kVPkn52ZxbU8",
        "outputId": "5326de56-9d36-4596-f49e-2dc38361fad8"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8112052</td>\n",
              "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8132799</td>\n",
              "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4655635</td>\n",
              "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9251303</td>\n",
              "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10067386</td>\n",
              "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                           document  label\n",
              "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
              "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
              "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
              "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
              "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Satro0bK25CA"
      },
      "source": [
        "## 데이터 섞기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Rj4fWpN523i8",
        "outputId": "d78c569a-851c-4b37-ef79-fd250d075511"
      },
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True) \n",
        "\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9045019</td>\n",
              "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6483659</td>\n",
              "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                           document  label\n",
              "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
              "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
              "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
              "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
              "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ke8GRyV3AMJ"
      },
      "source": [
        "## 필요 입출력 값 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrebOR3Ixtah"
      },
      "source": [
        "reviews = df.document.values.copy().astype(np.str)\n",
        "labels = df.label.values.copy().astype(np.int)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pPRFEcJEfrU",
        "outputId": "ed229d23-45d0-4b91-923c-a794a0307a5b"
      },
      "source": [
        "print(reviews.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200000,)\n",
            "(200000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KatYM0gqw69n"
      },
      "source": [
        "필요 시, 실습 시간 관계로 전체 20,000개 중에 2,000개만 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2od6yPKw1aC"
      },
      "source": [
        "# reviews = reviews[:2000]\n",
        "# labels = labels[:2000]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Rvjka1yNJhb"
      },
      "source": [
        "## 토큰나이저 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6_OFM9aLbUg"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME, cache_dir=CACHE_DIR, do_lower_case=False, model_max_length=SEQ_LENGTH)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1BOJT-vLbRo",
        "outputId": "60155494-1f87-4afa-9952-18c772be60cb"
      },
      "source": [
        "encoded_tokens= tokenizer.encode(\"토크나이징이 잘 될까여?\")\n",
        "print(encoded_tokens)\n",
        "print(tokenizer.decode(encoded_tokens))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 9873, 20308, 16439, 10739, 119233, 10739, 9654, 9100, 118671, 29935, 136, 102]\n",
            "[CLS] 토크나이징이 잘 될까여? [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9mDZ9ihLbMQ",
        "outputId": "6791f59a-ccff-4d62-f25b-84f4df038ed4"
      },
      "source": [
        "tokenized = tokenizer(\"토크나이징이 잘 될까여?\", max_length=20, padding='max_length')\n",
        "print(tokenized.keys())\n",
        "print(tokenized['input_ids'])\n",
        "print(tokenized['attention_mask'])\n",
        "print(tokenized['token_type_ids'])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
            "[101, 9873, 20308, 16439, 10739, 119233, 10739, 9654, 9100, 118671, 29935, 136, 102, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEnAfwf_Vb1I"
      },
      "source": [
        "## x, y 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4SlXQh2LwfI"
      },
      "source": [
        "\n",
        "tokernizer 사용 중에 경고 메시지가 많이 뜬다. 억제한다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twrpGcuELwfS"
      },
      "source": [
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7I3pUuBq7Ak"
      },
      "source": [
        "def build_model_input(reviews):\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  token_type_ids = []\n",
        "\n",
        "  for review in reviews:\n",
        "    tokenized = tokenizer(review, max_length=SEQ_LENGTH, padding='max_length')\n",
        "    # tokenized = {'input_ids': [101, ...], 'token_type_ids': [0, ...], 'attention_mask': [1, ...]}\n",
        "    input_ids.append(tokenized['input_ids'][:SEQ_LENGTH]) # 버그인지 몰라도 SEQ_LENGTH이상이어도 더 크게 나온다.\n",
        "    attention_masks.append(tokenized['attention_mask'][:SEQ_LENGTH])\n",
        "    token_type_ids.append(tokenized['token_type_ids'][:SEQ_LENGTH])\n",
        "\n",
        "  return (np.array(input_ids), np.array(attention_masks), np.array(token_type_ids))\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHtYY3r8LbJV"
      },
      "source": [
        "x = build_model_input(reviews)\n",
        "y = labels"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeELyXfvidtQ",
        "outputId": "2ca0d842-7642-4077-e1fd-cd8596a0c05b"
      },
      "source": [
        "print(x[0].shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200000, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HfIzDjeY0d7"
      },
      "source": [
        "## train/test 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxqohOmDa72g"
      },
      "source": [
        "def split_bert_data(x, y, test_ratio):\n",
        "  split_index = int(len(y)*(1-test_ratio))\n",
        "  train_x = (x[0][:split_index], x[1][:split_index], x[2][:split_index])\n",
        "  test_x  = (x[0][split_index:], x[1][split_index:], x[2][split_index:])\n",
        "  train_y, test_y = y[:split_index], y[split_index:]\n",
        "\n",
        "  return (train_x, train_y), (test_x, test_y)\n",
        "\n",
        "(train_x, train_y), (test_x, test_y) = split_bert_data(x, y, test_ratio=0.2)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWb-Ip8pYEQg"
      },
      "source": [
        "# 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Txqhf6XYFyP"
      },
      "source": [
        "## 모델 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-vXh3QmT5nu"
      },
      "source": [
        "from tensorflow.keras.initializers import TruncatedNormal\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "class TFBertClassifier(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(TFBertClassifier, self).__init__()\n",
        "\n",
        "    self.bert = TFBertModel.from_pretrained(BERT_MODEL_NAME, cache_dir=CACHE_DIR)\n",
        "    self.dropout = Dropout(self.bert.config.hidden_dropout_prob)\n",
        "    self.classifier = Dense(2, kernel_initializer=TruncatedNormal(self.bert.config.initializer_range), \n",
        "                            name=\"classifier\", activation=\"softmax\")\n",
        "\n",
        "  def call(self, inputs, attention_mask=None, token_type_ids=None, training=True):\n",
        "\n",
        "    outputs = self.bert(inputs, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "    # outputs 값: # sequence_output, pooled_output, (hidden_states), (attentions)\n",
        "    pooled_output = outputs[1] \n",
        "    pooled_output = self.dropout(pooled_output, training=training)\n",
        "    out = self.classifier(pooled_output)\n",
        "\n",
        "    return out\n",
        "\n",
        "model = TFBertClassifier()\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfycyrGDYg51"
      },
      "source": [
        "참고로 Bert의 default 설정은 다음과 같다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rFMC5hjYe93",
        "outputId": "5497bc4e-ba2d-4b97-968c-2c1c2820fe70"
      },
      "source": [
        "print(model.bert.config)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZIUqxuBbfq4"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "\n",
        "optimizer = Adam(3e-5)\n",
        "loss = SparseCategoricalCrossentropy()\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5JdxQn-bNPp"
      },
      "source": [
        "## 학습 실행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WU1NbHObNBY",
        "outputId": "0225c082-da08-4f9c-8259-a23a943f3d7f"
      },
      "source": [
        "history = model.fit(train_x, train_y, epochs=5, batch_size=32, validation_split=0.1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "4500/4500 [==============================] - 2180s 482ms/step - loss: 0.3849 - accuracy: 0.8238 - val_loss: 0.3197 - val_accuracy: 0.8586\n",
            "Epoch 2/5\n",
            "4500/4500 [==============================] - 2167s 482ms/step - loss: 0.2979 - accuracy: 0.8722 - val_loss: 0.3006 - val_accuracy: 0.8711\n",
            "Epoch 3/5\n",
            "4500/4500 [==============================] - 2167s 482ms/step - loss: 0.2465 - accuracy: 0.8979 - val_loss: 0.3163 - val_accuracy: 0.8669\n",
            "Epoch 4/5\n",
            "4500/4500 [==============================] - 2167s 482ms/step - loss: 0.1999 - accuracy: 0.9195 - val_loss: 0.3384 - val_accuracy: 0.8734\n",
            "Epoch 5/5\n",
            "4500/4500 [==============================] - 2167s 482ms/step - loss: 0.1632 - accuracy: 0.9352 - val_loss: 0.3503 - val_accuracy: 0.8729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JlJLgKw0iHT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cc04f44-ca0c-4313-a617-2b3bd669e3c1"
      },
      "source": [
        "loss, acc = model.evaluate(test_x, test_y, batch_size=32)\n",
        "print(\"loss =\", loss)\n",
        "print(\"acc =\", acc)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1250/1250 [==============================] - 184s 147ms/step - loss: 0.3579 - accuracy: 0.8687\n",
            "loss = 0.35785093903541565\n",
            "acc = 0.8687000274658203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvnNncG_3p87"
      },
      "source": [
        "## 분류 실행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNsQMfcjV5T8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e134043f-aa81-4a98-a7ed-4087e607682b"
      },
      "source": [
        "def do_classify(test_text):\n",
        "  model_input = build_model_input([test_text])\n",
        "  y_ = model.predict(model_input)\n",
        "  predicted = \"긍정\" if y_[0][1]>0.5 else \"부정\"\n",
        "\n",
        "  print(test_text, \"-->\", predicted, \",score :\",y_[0][1])\n",
        "\n",
        "do_classify(\"여운이 많이 남는 영화\")\n",
        "do_classify(\"여운이 많이 남는 영화. 스토리 전개는 뻔함.\")\n",
        "do_classify(\"여운이 많이 남는 영화. 스토리 전개는 뻔함. 시간 때우기 용\")\n",
        "do_classify(\"여운이 많이 남는 영화. 스토리 전개는 뻔함. 시간 때우기 용, 비추.\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "여운이 많이 남는 영화 --> 긍정 ,score : 0.9968172\n",
            "여운이 많이 남는 영화. 스토리 전개는 뻔함. --> 긍정 ,score : 0.9686366\n",
            "여운이 많이 남는 영화. 스토리 전개는 뻔함. 시간 때우기 용 --> 부정 ,score : 0.14527196\n",
            "여운이 많이 남는 영화. 스토리 전개는 뻔함. 시간 때우기 용, 비추. --> 부정 ,score : 0.16643839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QdBhU85rlY6"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": []
    }
  ]
}