{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "8팀_전석규.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSHrLmwrRDLz"
      },
      "source": [
        "#기본선언\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ppxv1TevNOJb"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Input, Reshape\n",
        "\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vFRZGyIRLqc"
      },
      "source": [
        "데이터 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-p62Zf9ROs7",
        "outputId": "84c67ab9-623c-45a6-d66d-67fd3a9f4e89"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YX-eNOfrWliR"
      },
      "source": [
        "test = '/content/gdrive/MyDrive/235626_컴퓨터 비전 학습 경진대회_data/test.csv'\n",
        "train = '/content/gdrive/MyDrive/235626_컴퓨터 비전 학습 경진대회_data/train.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0vykNpxj1pu"
      },
      "source": [
        "#데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "MexZjabnZMbL",
        "outputId": "3c481c26-7e8f-4165-ab04-53f88ce4c6f3"
      },
      "source": [
        "raw_test = pd.read_csv(test,encoding = 'CP949')\n",
        "raw_train = pd.read_csv(train,encoding = 'CP949')\n",
        "print(type(raw_test))\n",
        "print(type(raw_train))\n",
        "print(raw_test)\n",
        "print(raw_train)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0d706268452a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'CP949'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mraw_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'CP949'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtoSW90LaPKF",
        "outputId": "8096feab-deac-48c5-a062-9936acf4ca5e"
      },
      "source": [
        "print(raw_test)\n",
        "print(raw_train)\n",
        "train_img = raw_train.iloc[:,3:].to_numpy().reshape(-1,28,28)\n",
        "train_img1 = raw_train.iloc[:,3:].to_numpy().reshape(-1,28,28,1)\n",
        "train_digit = raw_train['digit']\n",
        "train_letter = raw_train['letter']\n",
        "test_img = raw_test.iloc[:,2:].to_numpy().reshape(-1,28,28)\n",
        "test_img1 = raw_test.iloc[:,2:].to_numpy().reshape(-1,28,28,1)\n",
        "test_letter = raw_test['letter']\n",
        "train_digit = raw_train['digit']\n",
        "print(type(train_digit))\n",
        "print(type(train_letter))\n",
        "print(type(test_letter))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          id letter  0  1  2  3  4  5  ...  776  777  778  779  780  781  782  783\n",
            "0       2049      L  0  4  0  2  4  2  ...    4    2    2    4    3    4    1    4\n",
            "1       2050      C  4  1  4  0  1  1  ...    2    4    2    4    2    2    1    2\n",
            "2       2051      S  0  4  0  1  3  2  ...    2    0    3    2    3    0    1    4\n",
            "3       2052      K  2  1  3  3  3  4  ...    3    2    4    1    0    4    4    4\n",
            "4       2053      W  1  0  1  1  2  2  ...    1    4    0    2    1    2    3    4\n",
            "...      ...    ... .. .. .. .. .. ..  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
            "20475  22524      P  1  2  1  1  0  0  ...    3    0    3    0    4    3    1    4\n",
            "20476  22525      S  4  1  1  4  0  0  ...    1    0    0    1    3    1    2    0\n",
            "20477  22526      B  4  2  1  3  2  1  ...    3    4    1    0    3    3    1    1\n",
            "20478  22527      K  1  1  2  3  4  0  ...    0    4    3    3    3    4    4    2\n",
            "20479  22528      S  2  1  0  3  0  3  ...    0    1    4    2    0    2    2    0\n",
            "\n",
            "[20480 rows x 786 columns]\n",
            "        id  digit letter  0  1  2  3  4  ...  776  777  778  779  780  781  782  783\n",
            "0        1      5      L  1  1  1  4  3  ...    0    1    2    4    4    4    3    4\n",
            "1        2      0      B  0  4  0  0  4  ...    0    1    4    1    4    2    1    2\n",
            "2        3      4      L  1  1  2  2  1  ...    3    0    2    0    3    0    2    2\n",
            "3        4      9      D  1  2  0  2  0  ...    2    0    1    4    0    0    1    1\n",
            "4        5      6      A  3  0  2  4  0  ...    3    2    1    3    4    3    1    2\n",
            "...    ...    ...    ... .. .. .. .. ..  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
            "2043  2044      6      V  2  4  3  4  2  ...    2    0    0    1    3    1    4    0\n",
            "2044  2045      1      L  3  2  2  1  1  ...    4    2    1    2    3    4    1    1\n",
            "2045  2046      9      A  4  0  4  0  2  ...    1    1    3    4    2    2    0    0\n",
            "2046  2047      0      Z  2  3  3  0  3  ...    1    1    0    4    1    4    3    1\n",
            "2047  2048      5      Z  4  2  2  1  3  ...    4    0    4    3    2    4    3    4\n",
            "\n",
            "[2048 rows x 787 columns]\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixooK8otjf63"
      },
      "source": [
        "#Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ln95flrgkHhF",
        "outputId": "479a2b42-4b5c-4bdb-8e0d-251767b7109c"
      },
      "source": [
        "print(train_img.max())\n",
        "print(test_img.max())\n",
        "train = train_img/255\n",
        "train1 = train_img1/255\n",
        "test = test_img/255\n",
        "test1 = test_img1/255\n",
        "print(np.max(train[:,]))\n",
        "print(np.max(test[:,]))\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "255\n",
            "255\n",
            "1.0\n",
            "1.0\n",
            "(2048, 28, 28)\n",
            "(20480, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND5PwdaAtzNH"
      },
      "source": [
        "#특징벡터, 대상벡터 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kX8R9yGjtyiA",
        "outputId": "2ceb6bce-417a-4af4-8565-3ad301a50684"
      },
      "source": [
        "train_X = train_img\n",
        "print(train_digit)\n",
        "print(type(train_digit))\n",
        "print(train_digit.to_numpy())\n",
        "print(type(train_digit.to_numpy()))\n",
        "train_y = train_digit.to_numpy()\n",
        "test_X = test_img\n",
        "print(type(train_X))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0       5\n",
            "1       0\n",
            "2       4\n",
            "3       9\n",
            "4       6\n",
            "       ..\n",
            "2043    6\n",
            "2044    1\n",
            "2045    9\n",
            "2046    0\n",
            "2047    5\n",
            "Name: digit, Length: 2048, dtype: int64\n",
            "<class 'pandas.core.series.Series'>\n",
            "[5 0 4 ... 9 0 5]\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8akANcir5_4"
      },
      "source": [
        "#Model 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f71tlITBU3jm"
      },
      "source": [
        "#템플릿 활용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WICyxGUmr9Bg",
        "outputId": "b5f4f2ce-442a-4d00-e913-a9dd66b6bd92"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(Input((28,28)))\n",
        "model.add(Reshape((28,28,1)))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.fit(train_X, train_y, epochs=100, verbose=1, batch_size=128, validation_split=0.1)\n",
        "\n",
        "\n",
        "# loss, acc = model.evaluate(test, test)\n",
        "# print(\"loss=\",loss)\n",
        "# print(\"acc=\",acc)\n",
        "\n",
        "# y_ = model.predict(test)\n",
        "# predicted = np.argmax(y_, axis=1)\n",
        "\n",
        "# print(predicted)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                16010     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 35,046\n",
            "Trainable params: 35,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 16s 26ms/step - loss: 4.0529 - accuracy: 0.0852 - val_loss: 2.3032 - val_accuracy: 0.1024\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3019 - accuracy: 0.1107 - val_loss: 2.3034 - val_accuracy: 0.1024\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3019 - accuracy: 0.1107 - val_loss: 2.3036 - val_accuracy: 0.1024\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3065 - accuracy: 0.1101 - val_loss: 2.3038 - val_accuracy: 0.1024\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3017 - accuracy: 0.1107 - val_loss: 2.3040 - val_accuracy: 0.1024\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3014 - accuracy: 0.1107 - val_loss: 2.3041 - val_accuracy: 0.1024\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3012 - accuracy: 0.1085 - val_loss: 2.3043 - val_accuracy: 0.0829\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3011 - accuracy: 0.1172 - val_loss: 2.3045 - val_accuracy: 0.0829\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3010 - accuracy: 0.1172 - val_loss: 2.3046 - val_accuracy: 0.0829\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3008 - accuracy: 0.1172 - val_loss: 2.3049 - val_accuracy: 0.0829\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3006 - accuracy: 0.1172 - val_loss: 2.3052 - val_accuracy: 0.0829\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.3004 - accuracy: 0.1172 - val_loss: 2.3054 - val_accuracy: 0.0829\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.3003 - accuracy: 0.1172 - val_loss: 2.3056 - val_accuracy: 0.0829\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3002 - accuracy: 0.1172 - val_loss: 2.3059 - val_accuracy: 0.0829\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3001 - accuracy: 0.1172 - val_loss: 2.3060 - val_accuracy: 0.0829\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3000 - accuracy: 0.1172 - val_loss: 2.3063 - val_accuracy: 0.0829\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2999 - accuracy: 0.1172 - val_loss: 2.3066 - val_accuracy: 0.0829\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2998 - accuracy: 0.1172 - val_loss: 2.3068 - val_accuracy: 0.0829\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2998 - accuracy: 0.1172 - val_loss: 2.3071 - val_accuracy: 0.0829\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2997 - accuracy: 0.1172 - val_loss: 2.3073 - val_accuracy: 0.0829\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.2996 - accuracy: 0.1172 - val_loss: 2.3075 - val_accuracy: 0.0829\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2996 - accuracy: 0.1172 - val_loss: 2.3079 - val_accuracy: 0.0829\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2995 - accuracy: 0.1172 - val_loss: 2.3081 - val_accuracy: 0.0829\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2995 - accuracy: 0.1172 - val_loss: 2.3084 - val_accuracy: 0.0829\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2994 - accuracy: 0.1172 - val_loss: 2.3086 - val_accuracy: 0.0829\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2994 - accuracy: 0.1172 - val_loss: 2.3089 - val_accuracy: 0.0829\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2993 - accuracy: 0.1172 - val_loss: 2.3091 - val_accuracy: 0.0829\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2993 - accuracy: 0.1172 - val_loss: 2.3093 - val_accuracy: 0.0829\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2992 - accuracy: 0.1172 - val_loss: 2.3096 - val_accuracy: 0.0829\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2992 - accuracy: 0.1172 - val_loss: 2.3097 - val_accuracy: 0.0829\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2991 - accuracy: 0.1172 - val_loss: 2.3099 - val_accuracy: 0.0829\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2991 - accuracy: 0.1172 - val_loss: 2.3101 - val_accuracy: 0.0829\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2991 - accuracy: 0.1172 - val_loss: 2.3102 - val_accuracy: 0.0829\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2991 - accuracy: 0.1172 - val_loss: 2.3104 - val_accuracy: 0.0829\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2991 - accuracy: 0.1172 - val_loss: 2.3106 - val_accuracy: 0.0829\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2990 - accuracy: 0.1172 - val_loss: 2.3107 - val_accuracy: 0.0829\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2990 - accuracy: 0.1172 - val_loss: 2.3109 - val_accuracy: 0.0829\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2990 - accuracy: 0.1172 - val_loss: 2.3111 - val_accuracy: 0.0829\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2990 - accuracy: 0.1172 - val_loss: 2.3111 - val_accuracy: 0.0829\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2990 - accuracy: 0.1172 - val_loss: 2.3113 - val_accuracy: 0.0829\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2990 - accuracy: 0.1172 - val_loss: 2.3113 - val_accuracy: 0.0829\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.2989 - accuracy: 0.1172 - val_loss: 2.3115 - val_accuracy: 0.0829\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2989 - accuracy: 0.1172 - val_loss: 2.3115 - val_accuracy: 0.0829\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2989 - accuracy: 0.1172 - val_loss: 2.3117 - val_accuracy: 0.0829\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2989 - accuracy: 0.1172 - val_loss: 2.3117 - val_accuracy: 0.0829\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2989 - accuracy: 0.1172 - val_loss: 2.3120 - val_accuracy: 0.0829\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2989 - accuracy: 0.1172 - val_loss: 2.3121 - val_accuracy: 0.0829\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2989 - accuracy: 0.1172 - val_loss: 2.3122 - val_accuracy: 0.0829\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.2989 - accuracy: 0.1172 - val_loss: 2.3123 - val_accuracy: 0.0829\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2989 - accuracy: 0.1172 - val_loss: 2.3125 - val_accuracy: 0.0829\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2989 - accuracy: 0.1172 - val_loss: 2.3126 - val_accuracy: 0.0829\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2989 - accuracy: 0.1172 - val_loss: 2.3129 - val_accuracy: 0.0829\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2988 - accuracy: 0.1172 - val_loss: 2.3128 - val_accuracy: 0.0829\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2989 - accuracy: 0.1172 - val_loss: 2.3128 - val_accuracy: 0.0829\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2989 - accuracy: 0.1172 - val_loss: 2.3128 - val_accuracy: 0.0829\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2988 - accuracy: 0.1172 - val_loss: 2.3129 - val_accuracy: 0.0829\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2989 - accuracy: 0.1172 - val_loss: 2.3132 - val_accuracy: 0.0829\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.2989 - accuracy: 0.1172 - val_loss: 2.3131 - val_accuracy: 0.0829\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2988 - accuracy: 0.1172 - val_loss: 2.3133 - val_accuracy: 0.0829\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2989 - accuracy: 0.1172 - val_loss: 2.3132 - val_accuracy: 0.0829\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2988 - accuracy: 0.1172 - val_loss: 2.3134 - val_accuracy: 0.0829\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2988 - accuracy: 0.1172 - val_loss: 2.3134 - val_accuracy: 0.0829\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2988 - accuracy: 0.1172 - val_loss: 2.3134 - val_accuracy: 0.0829\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2988 - accuracy: 0.1172 - val_loss: 2.3134 - val_accuracy: 0.0829\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2988 - accuracy: 0.1172 - val_loss: 2.3134 - val_accuracy: 0.0829\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2988 - accuracy: 0.1172 - val_loss: 2.3137 - val_accuracy: 0.0829\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2988 - accuracy: 0.1172 - val_loss: 2.3137 - val_accuracy: 0.0829\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2988 - accuracy: 0.1172 - val_loss: 2.3137 - val_accuracy: 0.0829\n",
            "Epoch 69/100\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 2.3067 - accuracy: 0.0938"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-38217809fe68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzjq6eulU7Te"
      },
      "source": [
        "#Dense 조절, 오버피팅 처리방법 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hZJe6gCQCEht",
        "outputId": "bc1e7b3b-ee13-4a9b-898b-9b8fc5cc0f20"
      },
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.regularizers import l1, l2, L1L2\n",
        "model = keras.Sequential()\n",
        "model.add(Input((28,28)))\n",
        "model.add(Reshape((28,28,1)))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu', kernel_regularizer=l2()))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(100, activation='relu', kernel_regularizer=l2()))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "history = model.fit(train_X, train_y, epochs=100, verbose=1, batch_size=128, validation_split=0.1)\n",
        "\n",
        "\n",
        "plt.plot(history.history['loss'], label='train_loss')\n",
        "plt.plot(history.history['val_loss'], label='test_loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 11, 11, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 100)               320100    \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 406,506\n",
            "Trainable params: 406,106\n",
            "Non-trainable params: 400\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 30ms/step - loss: 6.0539 - accuracy: 0.1384 - val_loss: 10.4825 - val_accuracy: 0.1073\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 5.5356 - accuracy: 0.1877 - val_loss: 8.2766 - val_accuracy: 0.1415\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 5.1676 - accuracy: 0.1975 - val_loss: 6.6033 - val_accuracy: 0.2293\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.8915 - accuracy: 0.2165 - val_loss: 5.2803 - val_accuracy: 0.1902\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.6662 - accuracy: 0.2219 - val_loss: 5.2610 - val_accuracy: 0.1659\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.4228 - accuracy: 0.2447 - val_loss: 4.6078 - val_accuracy: 0.2049\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.1636 - accuracy: 0.2599 - val_loss: 4.3341 - val_accuracy: 0.2098\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.9992 - accuracy: 0.2610 - val_loss: 3.7561 - val_accuracy: 0.2829\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.8367 - accuracy: 0.2724 - val_loss: 3.5079 - val_accuracy: 0.3122\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.6089 - accuracy: 0.2908 - val_loss: 3.6310 - val_accuracy: 0.2488\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.4872 - accuracy: 0.3044 - val_loss: 3.5964 - val_accuracy: 0.2244\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.2997 - accuracy: 0.3228 - val_loss: 3.2776 - val_accuracy: 0.3073\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.1604 - accuracy: 0.3511 - val_loss: 3.1833 - val_accuracy: 0.3220\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.0600 - accuracy: 0.3516 - val_loss: 3.2708 - val_accuracy: 0.2098\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.9702 - accuracy: 0.3652 - val_loss: 3.4107 - val_accuracy: 0.1561\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.8609 - accuracy: 0.3858 - val_loss: 3.3801 - val_accuracy: 0.1415\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.7226 - accuracy: 0.4075 - val_loss: 3.5414 - val_accuracy: 0.1220\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.6385 - accuracy: 0.4102 - val_loss: 3.5895 - val_accuracy: 0.0976\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.5742 - accuracy: 0.4324 - val_loss: 3.5181 - val_accuracy: 0.1122\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.4214 - accuracy: 0.4693 - val_loss: 3.5566 - val_accuracy: 0.1122\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.3356 - accuracy: 0.4943 - val_loss: 3.6944 - val_accuracy: 0.0976\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.1970 - accuracy: 0.5279 - val_loss: 3.7052 - val_accuracy: 0.1122\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.1402 - accuracy: 0.5269 - val_loss: 3.6901 - val_accuracy: 0.1122\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.0391 - accuracy: 0.5746 - val_loss: 3.7846 - val_accuracy: 0.1317\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.9442 - accuracy: 0.5990 - val_loss: 3.6285 - val_accuracy: 0.1073\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.9075 - accuracy: 0.6023 - val_loss: 3.8683 - val_accuracy: 0.1024\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.8318 - accuracy: 0.6240 - val_loss: 3.5757 - val_accuracy: 0.1024\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6733 - accuracy: 0.6717 - val_loss: 3.4717 - val_accuracy: 0.1073\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6127 - accuracy: 0.6994 - val_loss: 3.4806 - val_accuracy: 0.1122\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.5276 - accuracy: 0.7325 - val_loss: 3.3113 - val_accuracy: 0.1415\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.4220 - accuracy: 0.7591 - val_loss: 3.5369 - val_accuracy: 0.1268\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.3220 - accuracy: 0.7938 - val_loss: 3.2796 - val_accuracy: 0.1366\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.2753 - accuracy: 0.8085 - val_loss: 3.5186 - val_accuracy: 0.1415\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.2083 - accuracy: 0.8231 - val_loss: 3.3084 - val_accuracy: 0.1659\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.1319 - accuracy: 0.8416 - val_loss: 3.5762 - val_accuracy: 0.1512\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.1187 - accuracy: 0.8399 - val_loss: 3.2426 - val_accuracy: 0.2049\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.0552 - accuracy: 0.8730 - val_loss: 3.3153 - val_accuracy: 0.2098\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.0218 - accuracy: 0.8774 - val_loss: 3.0894 - val_accuracy: 0.2634\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.9873 - accuracy: 0.8833 - val_loss: 2.9640 - val_accuracy: 0.2878\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.9507 - accuracy: 0.8893 - val_loss: 2.7613 - val_accuracy: 0.4000\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.9213 - accuracy: 0.9023 - val_loss: 2.4438 - val_accuracy: 0.4195\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.8681 - accuracy: 0.9132 - val_loss: 2.9594 - val_accuracy: 0.3415\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.8538 - accuracy: 0.9061 - val_loss: 2.6097 - val_accuracy: 0.3805\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.8221 - accuracy: 0.9181 - val_loss: 2.2261 - val_accuracy: 0.4878\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.8031 - accuracy: 0.9246 - val_loss: 2.6865 - val_accuracy: 0.3659\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.8004 - accuracy: 0.9246 - val_loss: 2.1524 - val_accuracy: 0.5122\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.7918 - accuracy: 0.9267 - val_loss: 2.9115 - val_accuracy: 0.3317\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.7344 - accuracy: 0.9479 - val_loss: 2.1470 - val_accuracy: 0.5024\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.7064 - accuracy: 0.9485 - val_loss: 2.2180 - val_accuracy: 0.4829\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.6868 - accuracy: 0.9495 - val_loss: 2.3699 - val_accuracy: 0.4732\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.6820 - accuracy: 0.9436 - val_loss: 2.2011 - val_accuracy: 0.4683\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6761 - accuracy: 0.9436 - val_loss: 2.2373 - val_accuracy: 0.5122\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6566 - accuracy: 0.9501 - val_loss: 2.1320 - val_accuracy: 0.4976\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6619 - accuracy: 0.9392 - val_loss: 2.3944 - val_accuracy: 0.4878\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6584 - accuracy: 0.9354 - val_loss: 2.2116 - val_accuracy: 0.5171\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6576 - accuracy: 0.9376 - val_loss: 2.1073 - val_accuracy: 0.5220\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6488 - accuracy: 0.9436 - val_loss: 2.2899 - val_accuracy: 0.4976\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.6563 - accuracy: 0.9425 - val_loss: 2.5208 - val_accuracy: 0.4585\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.6654 - accuracy: 0.9322 - val_loss: 2.1556 - val_accuracy: 0.5415\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.6450 - accuracy: 0.9381 - val_loss: 2.6603 - val_accuracy: 0.4390\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.6468 - accuracy: 0.9403 - val_loss: 2.3590 - val_accuracy: 0.5073\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.6410 - accuracy: 0.9419 - val_loss: 2.3102 - val_accuracy: 0.4732\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.6394 - accuracy: 0.9447 - val_loss: 2.3918 - val_accuracy: 0.4927\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.6536 - accuracy: 0.9381 - val_loss: 2.3003 - val_accuracy: 0.5317\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6280 - accuracy: 0.9533 - val_loss: 2.2592 - val_accuracy: 0.5220\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6293 - accuracy: 0.9490 - val_loss: 2.3238 - val_accuracy: 0.5220\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.6327 - accuracy: 0.9474 - val_loss: 2.4866 - val_accuracy: 0.4732\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.6314 - accuracy: 0.9523 - val_loss: 2.2762 - val_accuracy: 0.5220\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5967 - accuracy: 0.9560 - val_loss: 2.2541 - val_accuracy: 0.5268\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.6081 - accuracy: 0.9474 - val_loss: 2.3351 - val_accuracy: 0.5463\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.6159 - accuracy: 0.9468 - val_loss: 2.4197 - val_accuracy: 0.5463\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6086 - accuracy: 0.9544 - val_loss: 2.3463 - val_accuracy: 0.5366\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5976 - accuracy: 0.9566 - val_loss: 2.2744 - val_accuracy: 0.5463\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5903 - accuracy: 0.9566 - val_loss: 2.2205 - val_accuracy: 0.5707\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5633 - accuracy: 0.9582 - val_loss: 2.2521 - val_accuracy: 0.5220\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5304 - accuracy: 0.9669 - val_loss: 2.2400 - val_accuracy: 0.5561\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5022 - accuracy: 0.9767 - val_loss: 2.2692 - val_accuracy: 0.5317\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5058 - accuracy: 0.9604 - val_loss: 2.1909 - val_accuracy: 0.5220\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4922 - accuracy: 0.9680 - val_loss: 2.3762 - val_accuracy: 0.5415\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.5113 - accuracy: 0.9577 - val_loss: 2.2503 - val_accuracy: 0.5220\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5232 - accuracy: 0.9577 - val_loss: 2.4481 - val_accuracy: 0.5512\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5248 - accuracy: 0.9555 - val_loss: 2.5463 - val_accuracy: 0.4439\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5348 - accuracy: 0.9588 - val_loss: 2.4743 - val_accuracy: 0.4780\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5748 - accuracy: 0.9485 - val_loss: 2.4897 - val_accuracy: 0.4878\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5609 - accuracy: 0.9571 - val_loss: 2.4805 - val_accuracy: 0.5073\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5581 - accuracy: 0.9598 - val_loss: 2.6300 - val_accuracy: 0.4244\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5789 - accuracy: 0.9495 - val_loss: 2.6189 - val_accuracy: 0.5171\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5801 - accuracy: 0.9495 - val_loss: 2.4862 - val_accuracy: 0.4927\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.5416 - accuracy: 0.9609 - val_loss: 2.4149 - val_accuracy: 0.5171\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4997 - accuracy: 0.9723 - val_loss: 2.4005 - val_accuracy: 0.5561\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4990 - accuracy: 0.9653 - val_loss: 2.5008 - val_accuracy: 0.5122\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4910 - accuracy: 0.9658 - val_loss: 2.7126 - val_accuracy: 0.4488\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4954 - accuracy: 0.9647 - val_loss: 2.3694 - val_accuracy: 0.4878\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5237 - accuracy: 0.9523 - val_loss: 2.9699 - val_accuracy: 0.4049\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.5092 - accuracy: 0.9626 - val_loss: 2.6356 - val_accuracy: 0.4634\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5222 - accuracy: 0.9598 - val_loss: 2.5200 - val_accuracy: 0.5122\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5239 - accuracy: 0.9598 - val_loss: 3.0019 - val_accuracy: 0.4927\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5356 - accuracy: 0.9571 - val_loss: 2.9284 - val_accuracy: 0.4341\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.5348 - accuracy: 0.9604 - val_loss: 2.4134 - val_accuracy: 0.5561\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5275 - accuracy: 0.9577 - val_loss: 2.5732 - val_accuracy: 0.5171\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-6LwZvoVLPP"
      },
      "source": [
        "#데이터 증강 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBLC87-T_79p"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32Q-qV119Tdf"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_X, val_X, train_y, val_y = train_test_split(train_X, train_y, test_size = 0.1, random_state = 1004)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyHHFdKz9TRN"
      },
      "source": [
        "test_image_datagen = ImageDataGenerator(\n",
        "  rescale=1./255\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ncw2hRU2lLQZ"
      },
      "source": [
        "train_image_datagen = ImageDataGenerator(\n",
        "  rescale=1./255, # 일반화\n",
        "  rotation_range=10,  # 랜덤하게 이미지를 회전 (단위: 도, 0-180)\n",
        "  zoom_range=0.1, # 랜덤하게 이미지 확대 (%)\n",
        "  width_shift_range=0.1,  # 랜덤하게 이미지를 수평으로 이동 (%)\n",
        "  height_shift_range=0.1,  # 랜덤하게 이미지를 수직으로 이동 (%)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoghsL8tyNOr",
        "outputId": "45f257d1-fd12-44f6-e7b9-af86049f0063"
      },
      "source": [
        "print(train_X.shape)\n",
        "print(train_y.shape)\n",
        "print(val_X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1750, 28, 28)\n",
            "(1750,)\n",
            "(195, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugnJjTx-v2JC",
        "outputId": "894d5f38-a92e-4488-b5ef-69414e597fb4"
      },
      "source": [
        "train_X = train_X.reshape(1750,28,28,1)\n",
        "val_X = val_X.reshape(195,28,28,1)\n",
        "print(train_X.shape)\n",
        "print(type(train_X))\n",
        "print(val_X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1750, 28, 28, 1)\n",
            "<class 'numpy.ndarray'>\n",
            "(195, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhW1lQBdVSfP"
      },
      "source": [
        "#Test digit데이터가 없어Train set에서 데이터를 떼어 내 validation set을 만듬"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QPiWn-MlK_Q"
      },
      "source": [
        "train_datagen = train_image_datagen.flow(\n",
        "     x=train_X,\n",
        "     y=train_y,\n",
        "     batch_size=256,\n",
        "     shuffle=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewAuhEKpHWZ4"
      },
      "source": [
        "test_datagen = test_image_datagen.flow(\n",
        "    x=val_X,\n",
        "    y=val_y,\n",
        "    batch_size=256,\n",
        "    shuffle=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w5atX435ywB7",
        "outputId": "479cd94d-0dbc-4058-c42c-cc355e0bcfe5"
      },
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.regularizers import l1, l2, L1L2\n",
        "model = keras.Sequential()\n",
        "model.add(Input((28,28)))\n",
        "model.add(Reshape((28,28,1)))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "#model.add(Dense(1000, activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.3))\n",
        "model.add(Dense(1000, activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.3))\n",
        "model.add(Dense(1000, activation='relu'))\n",
        "model.add(Dense(1000, activation='relu'))\n",
        "model.add(Dense(1000, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1000, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(train_datagen,\n",
        "          validation_data= test_datagen,\n",
        "          epochs=100)\n",
        "\n",
        "\n",
        "plt.plot(history.history['loss'], label='train_loss')\n",
        "plt.plot(history.history['val_loss'], label='test_loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_4 (Reshape)          (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 11, 11, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1000)              3201000   \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1000)              1001000   \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1000)              1001000   \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1000)              1001000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 1000)              1001000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 10)                10010     \n",
            "=================================================================\n",
            "Total params: 7,297,506\n",
            "Trainable params: 7,293,506\n",
            "Non-trainable params: 4,000\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\"), but it was called on an input with incompatible shape (None, None, None, None).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\"), but it was called on an input with incompatible shape (None, None, None, None).\n",
            "7/7 [==============================] - ETA: 0s - loss: 3.2050 - accuracy: 0.1389WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\"), but it was called on an input with incompatible shape (None, None, None, None).\n",
            "7/7 [==============================] - 1s 99ms/step - loss: 3.2050 - accuracy: 0.1389 - val_loss: 2.3164 - val_accuracy: 0.0974\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 2.7328 - accuracy: 0.1503 - val_loss: 3.2234 - val_accuracy: 0.1538\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 2.5859 - accuracy: 0.1760 - val_loss: 3.6247 - val_accuracy: 0.0974\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 2.4613 - accuracy: 0.1777 - val_loss: 3.3594 - val_accuracy: 0.1795\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 2.4454 - accuracy: 0.2046 - val_loss: 3.7218 - val_accuracy: 0.1333\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 2.4014 - accuracy: 0.2097 - val_loss: 3.9285 - val_accuracy: 0.1436\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 2.3291 - accuracy: 0.2257 - val_loss: 3.4703 - val_accuracy: 0.1795\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 2.3407 - accuracy: 0.2211 - val_loss: 3.3914 - val_accuracy: 0.1231\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 2.2729 - accuracy: 0.2303 - val_loss: 3.1565 - val_accuracy: 0.1590\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 1s 80ms/step - loss: 2.2067 - accuracy: 0.2503 - val_loss: 2.7581 - val_accuracy: 0.1641\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 2.1685 - accuracy: 0.2737 - val_loss: 2.6134 - val_accuracy: 0.1385\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 2.1139 - accuracy: 0.2994 - val_loss: 2.3886 - val_accuracy: 0.1128\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 2.1312 - accuracy: 0.2840 - val_loss: 2.1518 - val_accuracy: 0.2359\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 2.0956 - accuracy: 0.2943 - val_loss: 2.1431 - val_accuracy: 0.2513\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 70ms/step - loss: 2.0873 - accuracy: 0.2920 - val_loss: 1.9749 - val_accuracy: 0.2205\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 2.0181 - accuracy: 0.3263 - val_loss: 1.9949 - val_accuracy: 0.2923\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 1.9754 - accuracy: 0.3331 - val_loss: 2.1271 - val_accuracy: 0.2410\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 1.9340 - accuracy: 0.3531 - val_loss: 2.2327 - val_accuracy: 0.1744\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 70ms/step - loss: 1.8670 - accuracy: 0.3594 - val_loss: 2.2305 - val_accuracy: 0.1333\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 1.7946 - accuracy: 0.3783 - val_loss: 2.1449 - val_accuracy: 0.2256\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 1.7808 - accuracy: 0.3960 - val_loss: 2.1055 - val_accuracy: 0.2154\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 69ms/step - loss: 1.7381 - accuracy: 0.4017 - val_loss: 1.9277 - val_accuracy: 0.2821\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 69ms/step - loss: 1.6817 - accuracy: 0.4400 - val_loss: 1.9059 - val_accuracy: 0.3744\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 69ms/step - loss: 1.6115 - accuracy: 0.4474 - val_loss: 1.9814 - val_accuracy: 0.2769\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 1.6281 - accuracy: 0.4520 - val_loss: 1.9555 - val_accuracy: 0.3231\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 1.5514 - accuracy: 0.4749 - val_loss: 1.9459 - val_accuracy: 0.2615\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 71ms/step - loss: 1.5628 - accuracy: 0.4714 - val_loss: 2.0978 - val_accuracy: 0.2410\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 70ms/step - loss: 1.4383 - accuracy: 0.5097 - val_loss: 2.0671 - val_accuracy: 0.2410\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 1.4719 - accuracy: 0.4966 - val_loss: 2.1816 - val_accuracy: 0.2718\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 1.3707 - accuracy: 0.5126 - val_loss: 1.6488 - val_accuracy: 0.4564\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 1.3706 - accuracy: 0.5354 - val_loss: 1.7607 - val_accuracy: 0.3795\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 1.3087 - accuracy: 0.5354 - val_loss: 1.6364 - val_accuracy: 0.4872\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 1.3161 - accuracy: 0.5600 - val_loss: 1.7568 - val_accuracy: 0.4103\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 69ms/step - loss: 1.2740 - accuracy: 0.5554 - val_loss: 1.8164 - val_accuracy: 0.3282\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 1.2413 - accuracy: 0.5737 - val_loss: 1.8610 - val_accuracy: 0.3897\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 1.1798 - accuracy: 0.5943 - val_loss: 1.7541 - val_accuracy: 0.4308\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 1.2215 - accuracy: 0.5817 - val_loss: 1.6399 - val_accuracy: 0.4359\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 1.1700 - accuracy: 0.6040 - val_loss: 1.7355 - val_accuracy: 0.4564\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 1.1493 - accuracy: 0.6149 - val_loss: 1.8645 - val_accuracy: 0.3846\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 1s 75ms/step - loss: 1.1015 - accuracy: 0.6257 - val_loss: 1.5291 - val_accuracy: 0.4308\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 1s 75ms/step - loss: 1.0895 - accuracy: 0.6343 - val_loss: 1.4178 - val_accuracy: 0.5231\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 1.0373 - accuracy: 0.6377 - val_loss: 1.6110 - val_accuracy: 0.4769\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 0.9645 - accuracy: 0.6674 - val_loss: 1.4907 - val_accuracy: 0.4923\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 1.0346 - accuracy: 0.6606 - val_loss: 1.7104 - val_accuracy: 0.3846\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 0.9239 - accuracy: 0.6811 - val_loss: 1.5869 - val_accuracy: 0.4615\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 0.9332 - accuracy: 0.6794 - val_loss: 1.4093 - val_accuracy: 0.4974\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 0.8851 - accuracy: 0.6994 - val_loss: 1.5862 - val_accuracy: 0.4923\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 0.8693 - accuracy: 0.7074 - val_loss: 1.3045 - val_accuracy: 0.5949\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 0.8208 - accuracy: 0.7051 - val_loss: 1.6889 - val_accuracy: 0.4615\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 0.8235 - accuracy: 0.7229 - val_loss: 1.7407 - val_accuracy: 0.4564\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 0.7708 - accuracy: 0.7451 - val_loss: 1.5166 - val_accuracy: 0.5179\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 0.7774 - accuracy: 0.7526 - val_loss: 1.4475 - val_accuracy: 0.5385\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 0.7523 - accuracy: 0.7394 - val_loss: 1.5191 - val_accuracy: 0.5077\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 0.7218 - accuracy: 0.7446 - val_loss: 1.3190 - val_accuracy: 0.5487\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 0.7480 - accuracy: 0.7434 - val_loss: 1.4219 - val_accuracy: 0.4974\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 0.7274 - accuracy: 0.7509 - val_loss: 1.3327 - val_accuracy: 0.6051\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 0.7604 - accuracy: 0.7451 - val_loss: 1.3810 - val_accuracy: 0.5590\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 0.7661 - accuracy: 0.7366 - val_loss: 1.6867 - val_accuracy: 0.5333\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 0.6967 - accuracy: 0.7646 - val_loss: 1.4884 - val_accuracy: 0.5744\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 0.7563 - accuracy: 0.7469 - val_loss: 1.7349 - val_accuracy: 0.4821\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 0.7226 - accuracy: 0.7566 - val_loss: 1.3885 - val_accuracy: 0.5231\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 0.6653 - accuracy: 0.7697 - val_loss: 1.6947 - val_accuracy: 0.4974\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 0.6336 - accuracy: 0.7914 - val_loss: 1.8363 - val_accuracy: 0.5077\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 0.6266 - accuracy: 0.7949 - val_loss: 1.3989 - val_accuracy: 0.5795\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 0.5754 - accuracy: 0.7983 - val_loss: 1.3591 - val_accuracy: 0.5897\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 0.6001 - accuracy: 0.8034 - val_loss: 1.5552 - val_accuracy: 0.5436\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 0.5679 - accuracy: 0.8069 - val_loss: 1.3469 - val_accuracy: 0.6154\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 0.5215 - accuracy: 0.8109 - val_loss: 1.5974 - val_accuracy: 0.5692\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 0.5617 - accuracy: 0.8137 - val_loss: 1.4973 - val_accuracy: 0.6205\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 0.5739 - accuracy: 0.8103 - val_loss: 1.5972 - val_accuracy: 0.6103\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 0.5139 - accuracy: 0.8217 - val_loss: 1.7108 - val_accuracy: 0.5641\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 1s 76ms/step - loss: 0.5003 - accuracy: 0.8320 - val_loss: 1.7143 - val_accuracy: 0.5231\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 0.4935 - accuracy: 0.8331 - val_loss: 1.6360 - val_accuracy: 0.5897\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 0.4645 - accuracy: 0.8394 - val_loss: 2.1168 - val_accuracy: 0.5077\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 1s 77ms/step - loss: 0.4837 - accuracy: 0.8509 - val_loss: 1.5359 - val_accuracy: 0.5949\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 0.4578 - accuracy: 0.8411 - val_loss: 1.7027 - val_accuracy: 0.5949\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 0.4652 - accuracy: 0.8451 - val_loss: 2.0463 - val_accuracy: 0.5282\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 69ms/step - loss: 0.4032 - accuracy: 0.8623 - val_loss: 1.5471 - val_accuracy: 0.6103\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 1s 75ms/step - loss: 0.3722 - accuracy: 0.8726 - val_loss: 1.5397 - val_accuracy: 0.6205\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 0.4017 - accuracy: 0.8594 - val_loss: 1.7095 - val_accuracy: 0.5795\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 0.4007 - accuracy: 0.8617 - val_loss: 1.7607 - val_accuracy: 0.5590\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 0.3777 - accuracy: 0.8691 - val_loss: 1.7003 - val_accuracy: 0.5487\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 0.4143 - accuracy: 0.8577 - val_loss: 1.8038 - val_accuracy: 0.5692\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 0.4021 - accuracy: 0.8617 - val_loss: 1.9345 - val_accuracy: 0.5538\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 0.3956 - accuracy: 0.8606 - val_loss: 1.8343 - val_accuracy: 0.5641\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 1s 75ms/step - loss: 0.3820 - accuracy: 0.8817 - val_loss: 2.5018 - val_accuracy: 0.5590\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 0.3650 - accuracy: 0.8766 - val_loss: 2.2610 - val_accuracy: 0.5846\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 0.3362 - accuracy: 0.8920 - val_loss: 1.6477 - val_accuracy: 0.6410\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 0.3362 - accuracy: 0.8874 - val_loss: 1.8371 - val_accuracy: 0.5846\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 0.3383 - accuracy: 0.8817 - val_loss: 1.9837 - val_accuracy: 0.5333\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 0.3773 - accuracy: 0.8737 - val_loss: 2.2782 - val_accuracy: 0.5231\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 0.3260 - accuracy: 0.8943 - val_loss: 1.9897 - val_accuracy: 0.5846\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 0.3509 - accuracy: 0.8777 - val_loss: 2.0420 - val_accuracy: 0.5487\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 0.2958 - accuracy: 0.8966 - val_loss: 1.9191 - val_accuracy: 0.5692\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 70ms/step - loss: 0.3526 - accuracy: 0.8909 - val_loss: 2.5659 - val_accuracy: 0.5026\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 1s 75ms/step - loss: 0.3238 - accuracy: 0.8897 - val_loss: 2.3837 - val_accuracy: 0.5128\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 0.3218 - accuracy: 0.8937 - val_loss: 2.3439 - val_accuracy: 0.5436\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 0.3035 - accuracy: 0.8989 - val_loss: 1.8806 - val_accuracy: 0.5692\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 0.3031 - accuracy: 0.8989 - val_loss: 2.3510 - val_accuracy: 0.5590\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 0.3257 - accuracy: 0.8903 - val_loss: 2.2131 - val_accuracy: 0.5231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WIjCVAfWAXY"
      },
      "source": [
        "#Loss는 다소 낮아졌지만 Accuracy가 감소함\n",
        "\n",
        "##Train set이 적은데 더 나누어서 그런듯 함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpZ_LwabWGoA"
      },
      "source": [
        "#성능 개선 방안\n",
        "\n",
        "##-더 많은 train set을 모은다.\n",
        "###-resnet18등 다른 모델을 적용해 본다."
      ]
    }
  ]
}