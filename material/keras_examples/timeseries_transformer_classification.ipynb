{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "timeseries_transformer_classification",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ChRNPgZp62x"
      },
      "source": [
        "# Timeseries classification with a Transformer model\n",
        "\n",
        "copy from https://keras.io/examples/timeseries/timeseries_classification_transformer/\n",
        "\n",
        "Example Key Word : 시계열 데이터, Transformer, 분류"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbT4WxcqqV0a"
      },
      "source": [
        "Transformer 모델을 시계열 데이터에 적용한 것\n",
        "\n",
        "\n",
        "Timeseries classification from scratch 와 거의 동일하고 오로지 모델만 바꾸었다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AazuugCqc5I"
      },
      "source": [
        "# 데이터 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqtiKphvp621"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def readucr(filename):\n",
        "    data = np.loadtxt(filename, delimiter=\"\\t\")\n",
        "    y = data[:, 0]\n",
        "    x = data[:, 1:]\n",
        "    return x, y.astype(int)\n",
        "\n",
        "\n",
        "root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n",
        "\n",
        "x_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n",
        "x_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")\n",
        "\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
        "\n",
        "n_classes = len(np.unique(y_train))\n",
        "\n",
        "idx = np.random.permutation(len(x_train))\n",
        "x_train = x_train[idx]\n",
        "y_train = y_train[idx]\n",
        "\n",
        "y_train[y_train == -1] = 0\n",
        "y_test[y_test == -1] = 0"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AK1vaOzr3GE"
      },
      "source": [
        "# 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2S149A3qyd5"
      },
      "source": [
        "## 모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czD-KgQxp623"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEqEgG8Zq_DD"
      },
      "source": [
        "transformer encoder 블럭 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImLp3vA4p624"
      },
      "source": [
        "\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Normalization and Attention\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(x, x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    return x + res\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2NNUBuUrKzQ"
      },
      "source": [
        "transformer encoder 블럭을 쌓아서 전체 모델을 정의한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_29cLPQfp626"
      },
      "source": [
        "def build_model(\n",
        "    input_shape,\n",
        "    head_size,\n",
        "    num_heads,\n",
        "    ff_dim,\n",
        "    num_transformer_blocks,\n",
        "    mlp_units,\n",
        "    dropout=0,\n",
        "    mlp_dropout=0,\n",
        "):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    # flatten() 대신 GloabalAveragePooling1D()를 사용하였다.\n",
        "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
        "    for dim in mlp_units:\n",
        "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(mlp_dropout)(x)\n",
        "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
        "    return keras.Model(inputs, outputs)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT4dQifjrscE"
      },
      "source": [
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "model = build_model(\n",
        "    input_shape,\n",
        "    head_size=256,\n",
        "    num_heads=4,\n",
        "    ff_dim=4,\n",
        "    num_transformer_blocks=4,\n",
        "    mlp_units=[128],\n",
        "    mlp_dropout=0.4,\n",
        "    dropout=0.25,\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aKOXPPnr8oZ"
      },
      "source": [
        "## 컴파일"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geLIdNdMr7dx",
        "outputId": "512e3edb-054f-495e-af67-18d3db554f5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "model.summary()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 500, 1)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_8 (LayerNor (None, 500, 1)       2           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_4 (MultiHe (None, 500, 1)       7169        layer_normalization_8[0][0]      \n",
            "                                                                 layer_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 500, 1)       0           multi_head_attention_4[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_8 (TFOpLam (None, 500, 1)       0           dropout_9[0][0]                  \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_9 (LayerNor (None, 500, 1)       2           tf.__operators__.add_8[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_8 (Conv1D)               (None, 500, 4)       8           layer_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 500, 4)       0           conv1d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_9 (Conv1D)               (None, 500, 1)       5           dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_9 (TFOpLam (None, 500, 1)       0           conv1d_9[0][0]                   \n",
            "                                                                 tf.__operators__.add_8[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_10 (LayerNo (None, 500, 1)       2           tf.__operators__.add_9[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_5 (MultiHe (None, 500, 1)       7169        layer_normalization_10[0][0]     \n",
            "                                                                 layer_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 500, 1)       0           multi_head_attention_5[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_10 (TFOpLa (None, 500, 1)       0           dropout_11[0][0]                 \n",
            "                                                                 tf.__operators__.add_9[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_11 (LayerNo (None, 500, 1)       2           tf.__operators__.add_10[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_10 (Conv1D)              (None, 500, 4)       8           layer_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 500, 4)       0           conv1d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_11 (Conv1D)              (None, 500, 1)       5           dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_11 (TFOpLa (None, 500, 1)       0           conv1d_11[0][0]                  \n",
            "                                                                 tf.__operators__.add_10[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_12 (LayerNo (None, 500, 1)       2           tf.__operators__.add_11[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_6 (MultiHe (None, 500, 1)       7169        layer_normalization_12[0][0]     \n",
            "                                                                 layer_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 500, 1)       0           multi_head_attention_6[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_12 (TFOpLa (None, 500, 1)       0           dropout_13[0][0]                 \n",
            "                                                                 tf.__operators__.add_11[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_13 (LayerNo (None, 500, 1)       2           tf.__operators__.add_12[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_12 (Conv1D)              (None, 500, 4)       8           layer_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 500, 4)       0           conv1d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_13 (Conv1D)              (None, 500, 1)       5           dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_13 (TFOpLa (None, 500, 1)       0           conv1d_13[0][0]                  \n",
            "                                                                 tf.__operators__.add_12[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_14 (LayerNo (None, 500, 1)       2           tf.__operators__.add_13[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_7 (MultiHe (None, 500, 1)       7169        layer_normalization_14[0][0]     \n",
            "                                                                 layer_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 500, 1)       0           multi_head_attention_7[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_14 (TFOpLa (None, 500, 1)       0           dropout_15[0][0]                 \n",
            "                                                                 tf.__operators__.add_13[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_15 (LayerNo (None, 500, 1)       2           tf.__operators__.add_14[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_14 (Conv1D)              (None, 500, 4)       8           layer_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 500, 4)       0           conv1d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_15 (Conv1D)              (None, 500, 1)       5           dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_15 (TFOpLa (None, 500, 1)       0           conv1d_15[0][0]                  \n",
            "                                                                 tf.__operators__.add_14[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_1 (Glo (None, 500)          0           tf.__operators__.add_15[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 128)          64128       global_average_pooling1d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 128)          0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            258         dropout_17[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 93,130\n",
            "Trainable params: 93,130\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoqjGoscp626"
      },
      "source": [
        "## 학습 실행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxqI3y8yp627",
        "outputId": "1da38fa6-4e19-4913-d1af-25c68fe64a99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
        "\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=200,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "23/23 [==============================] - 27s 1s/step - loss: 1.0886 - sparse_categorical_accuracy: 0.5184 - val_loss: 0.7760 - val_sparse_categorical_accuracy: 0.5492\n",
            "Epoch 2/200\n",
            "23/23 [==============================] - 25s 1s/step - loss: 0.9776 - sparse_categorical_accuracy: 0.5299 - val_loss: 0.6986 - val_sparse_categorical_accuracy: 0.5964\n",
            "Epoch 3/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.8754 - sparse_categorical_accuracy: 0.5736 - val_loss: 0.6517 - val_sparse_categorical_accuracy: 0.6283\n",
            "Epoch 4/200\n",
            "23/23 [==============================] - 23s 1s/step - loss: 0.8189 - sparse_categorical_accuracy: 0.5816 - val_loss: 0.6229 - val_sparse_categorical_accuracy: 0.6560\n",
            "Epoch 5/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.7812 - sparse_categorical_accuracy: 0.6083 - val_loss: 0.5996 - val_sparse_categorical_accuracy: 0.6852\n",
            "Epoch 6/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.7499 - sparse_categorical_accuracy: 0.6250 - val_loss: 0.5841 - val_sparse_categorical_accuracy: 0.6893\n",
            "Epoch 7/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.6981 - sparse_categorical_accuracy: 0.6438 - val_loss: 0.5705 - val_sparse_categorical_accuracy: 0.7018\n",
            "Epoch 8/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.6870 - sparse_categorical_accuracy: 0.6569 - val_loss: 0.5610 - val_sparse_categorical_accuracy: 0.7129\n",
            "Epoch 9/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.6572 - sparse_categorical_accuracy: 0.6681 - val_loss: 0.5526 - val_sparse_categorical_accuracy: 0.7254\n",
            "Epoch 10/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.6704 - sparse_categorical_accuracy: 0.6597 - val_loss: 0.5449 - val_sparse_categorical_accuracy: 0.7282\n",
            "Epoch 11/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.6444 - sparse_categorical_accuracy: 0.6701 - val_loss: 0.5406 - val_sparse_categorical_accuracy: 0.7240\n",
            "Epoch 12/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.6209 - sparse_categorical_accuracy: 0.6903 - val_loss: 0.5364 - val_sparse_categorical_accuracy: 0.7379\n",
            "Epoch 13/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.6065 - sparse_categorical_accuracy: 0.6983 - val_loss: 0.5341 - val_sparse_categorical_accuracy: 0.7254\n",
            "Epoch 14/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.5855 - sparse_categorical_accuracy: 0.7069 - val_loss: 0.5269 - val_sparse_categorical_accuracy: 0.7448\n",
            "Epoch 15/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.5905 - sparse_categorical_accuracy: 0.7115 - val_loss: 0.5204 - val_sparse_categorical_accuracy: 0.7462\n",
            "Epoch 16/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.5589 - sparse_categorical_accuracy: 0.7191 - val_loss: 0.5168 - val_sparse_categorical_accuracy: 0.7406\n",
            "Epoch 17/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.5608 - sparse_categorical_accuracy: 0.7201 - val_loss: 0.5108 - val_sparse_categorical_accuracy: 0.7420\n",
            "Epoch 18/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.5415 - sparse_categorical_accuracy: 0.7337 - val_loss: 0.5066 - val_sparse_categorical_accuracy: 0.7448\n",
            "Epoch 19/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7240 - val_loss: 0.5037 - val_sparse_categorical_accuracy: 0.7448\n",
            "Epoch 20/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.5291 - sparse_categorical_accuracy: 0.7451 - val_loss: 0.4992 - val_sparse_categorical_accuracy: 0.7531\n",
            "Epoch 21/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.5476 - sparse_categorical_accuracy: 0.7361 - val_loss: 0.4959 - val_sparse_categorical_accuracy: 0.7531\n",
            "Epoch 22/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.5321 - sparse_categorical_accuracy: 0.7337 - val_loss: 0.4897 - val_sparse_categorical_accuracy: 0.7531\n",
            "Epoch 23/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.5165 - sparse_categorical_accuracy: 0.7451 - val_loss: 0.4871 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 24/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.4861 - sparse_categorical_accuracy: 0.7597 - val_loss: 0.4835 - val_sparse_categorical_accuracy: 0.7573\n",
            "Epoch 25/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.4961 - sparse_categorical_accuracy: 0.7628 - val_loss: 0.4816 - val_sparse_categorical_accuracy: 0.7559\n",
            "Epoch 26/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.4861 - sparse_categorical_accuracy: 0.7677 - val_loss: 0.4785 - val_sparse_categorical_accuracy: 0.7642\n",
            "Epoch 27/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.4963 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.4762 - val_sparse_categorical_accuracy: 0.7628\n",
            "Epoch 28/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.4648 - sparse_categorical_accuracy: 0.7785 - val_loss: 0.4711 - val_sparse_categorical_accuracy: 0.7642\n",
            "Epoch 29/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.4632 - sparse_categorical_accuracy: 0.7819 - val_loss: 0.4686 - val_sparse_categorical_accuracy: 0.7656\n",
            "Epoch 30/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.4570 - sparse_categorical_accuracy: 0.7865 - val_loss: 0.4677 - val_sparse_categorical_accuracy: 0.7684\n",
            "Epoch 31/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.4511 - sparse_categorical_accuracy: 0.7934 - val_loss: 0.4656 - val_sparse_categorical_accuracy: 0.7684\n",
            "Epoch 32/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.4427 - sparse_categorical_accuracy: 0.7951 - val_loss: 0.4647 - val_sparse_categorical_accuracy: 0.7670\n",
            "Epoch 33/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.4404 - sparse_categorical_accuracy: 0.7941 - val_loss: 0.4604 - val_sparse_categorical_accuracy: 0.7767\n",
            "Epoch 34/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.4531 - sparse_categorical_accuracy: 0.7896 - val_loss: 0.4579 - val_sparse_categorical_accuracy: 0.7753\n",
            "Epoch 35/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.4299 - sparse_categorical_accuracy: 0.8014 - val_loss: 0.4572 - val_sparse_categorical_accuracy: 0.7781\n",
            "Epoch 36/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.4209 - sparse_categorical_accuracy: 0.8115 - val_loss: 0.4546 - val_sparse_categorical_accuracy: 0.7822\n",
            "Epoch 37/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.4421 - sparse_categorical_accuracy: 0.7927 - val_loss: 0.4504 - val_sparse_categorical_accuracy: 0.7809\n",
            "Epoch 38/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.4219 - sparse_categorical_accuracy: 0.8083 - val_loss: 0.4477 - val_sparse_categorical_accuracy: 0.7850\n",
            "Epoch 39/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.4080 - sparse_categorical_accuracy: 0.8198 - val_loss: 0.4441 - val_sparse_categorical_accuracy: 0.7850\n",
            "Epoch 40/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.4192 - sparse_categorical_accuracy: 0.8108 - val_loss: 0.4417 - val_sparse_categorical_accuracy: 0.7892\n",
            "Epoch 41/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.4106 - sparse_categorical_accuracy: 0.8135 - val_loss: 0.4397 - val_sparse_categorical_accuracy: 0.7892\n",
            "Epoch 42/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.4044 - sparse_categorical_accuracy: 0.8201 - val_loss: 0.4379 - val_sparse_categorical_accuracy: 0.7920\n",
            "Epoch 43/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3969 - sparse_categorical_accuracy: 0.8208 - val_loss: 0.4361 - val_sparse_categorical_accuracy: 0.7989\n",
            "Epoch 44/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3926 - sparse_categorical_accuracy: 0.8205 - val_loss: 0.4350 - val_sparse_categorical_accuracy: 0.7947\n",
            "Epoch 45/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3721 - sparse_categorical_accuracy: 0.8368 - val_loss: 0.4329 - val_sparse_categorical_accuracy: 0.7989\n",
            "Epoch 46/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3940 - sparse_categorical_accuracy: 0.8184 - val_loss: 0.4285 - val_sparse_categorical_accuracy: 0.8058\n",
            "Epoch 47/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3750 - sparse_categorical_accuracy: 0.8385 - val_loss: 0.4276 - val_sparse_categorical_accuracy: 0.8031\n",
            "Epoch 48/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3800 - sparse_categorical_accuracy: 0.8295 - val_loss: 0.4264 - val_sparse_categorical_accuracy: 0.8044\n",
            "Epoch 49/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3714 - sparse_categorical_accuracy: 0.8399 - val_loss: 0.4223 - val_sparse_categorical_accuracy: 0.8128\n",
            "Epoch 50/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3796 - sparse_categorical_accuracy: 0.8396 - val_loss: 0.4209 - val_sparse_categorical_accuracy: 0.8086\n",
            "Epoch 51/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3645 - sparse_categorical_accuracy: 0.8441 - val_loss: 0.4186 - val_sparse_categorical_accuracy: 0.8086\n",
            "Epoch 52/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3679 - sparse_categorical_accuracy: 0.8441 - val_loss: 0.4182 - val_sparse_categorical_accuracy: 0.8100\n",
            "Epoch 53/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3609 - sparse_categorical_accuracy: 0.8507 - val_loss: 0.4133 - val_sparse_categorical_accuracy: 0.8183\n",
            "Epoch 54/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3601 - sparse_categorical_accuracy: 0.8441 - val_loss: 0.4175 - val_sparse_categorical_accuracy: 0.8169\n",
            "Epoch 55/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3563 - sparse_categorical_accuracy: 0.8451 - val_loss: 0.4117 - val_sparse_categorical_accuracy: 0.8169\n",
            "Epoch 56/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3454 - sparse_categorical_accuracy: 0.8503 - val_loss: 0.4101 - val_sparse_categorical_accuracy: 0.8183\n",
            "Epoch 57/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3303 - sparse_categorical_accuracy: 0.8608 - val_loss: 0.4100 - val_sparse_categorical_accuracy: 0.8155\n",
            "Epoch 58/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3432 - sparse_categorical_accuracy: 0.8580 - val_loss: 0.4086 - val_sparse_categorical_accuracy: 0.8169\n",
            "Epoch 59/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3460 - sparse_categorical_accuracy: 0.8514 - val_loss: 0.4053 - val_sparse_categorical_accuracy: 0.8183\n",
            "Epoch 60/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3245 - sparse_categorical_accuracy: 0.8670 - val_loss: 0.4025 - val_sparse_categorical_accuracy: 0.8266\n",
            "Epoch 61/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3336 - sparse_categorical_accuracy: 0.8611 - val_loss: 0.4036 - val_sparse_categorical_accuracy: 0.8252\n",
            "Epoch 62/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3180 - sparse_categorical_accuracy: 0.8674 - val_loss: 0.4028 - val_sparse_categorical_accuracy: 0.8211\n",
            "Epoch 63/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3317 - sparse_categorical_accuracy: 0.8604 - val_loss: 0.4021 - val_sparse_categorical_accuracy: 0.8280\n",
            "Epoch 64/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3227 - sparse_categorical_accuracy: 0.8656 - val_loss: 0.4008 - val_sparse_categorical_accuracy: 0.8266\n",
            "Epoch 65/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3198 - sparse_categorical_accuracy: 0.8628 - val_loss: 0.3979 - val_sparse_categorical_accuracy: 0.8280\n",
            "Epoch 66/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3139 - sparse_categorical_accuracy: 0.8698 - val_loss: 0.3961 - val_sparse_categorical_accuracy: 0.8308\n",
            "Epoch 67/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3172 - sparse_categorical_accuracy: 0.8694 - val_loss: 0.3976 - val_sparse_categorical_accuracy: 0.8239\n",
            "Epoch 68/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3100 - sparse_categorical_accuracy: 0.8729 - val_loss: 0.3936 - val_sparse_categorical_accuracy: 0.8322\n",
            "Epoch 69/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3122 - sparse_categorical_accuracy: 0.8691 - val_loss: 0.3923 - val_sparse_categorical_accuracy: 0.8252\n",
            "Epoch 70/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3115 - sparse_categorical_accuracy: 0.8740 - val_loss: 0.3908 - val_sparse_categorical_accuracy: 0.8363\n",
            "Epoch 71/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3062 - sparse_categorical_accuracy: 0.8743 - val_loss: 0.3882 - val_sparse_categorical_accuracy: 0.8336\n",
            "Epoch 72/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2910 - sparse_categorical_accuracy: 0.8865 - val_loss: 0.3907 - val_sparse_categorical_accuracy: 0.8322\n",
            "Epoch 73/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3004 - sparse_categorical_accuracy: 0.8764 - val_loss: 0.3894 - val_sparse_categorical_accuracy: 0.8350\n",
            "Epoch 74/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2935 - sparse_categorical_accuracy: 0.8896 - val_loss: 0.3849 - val_sparse_categorical_accuracy: 0.8419\n",
            "Epoch 75/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3057 - sparse_categorical_accuracy: 0.8753 - val_loss: 0.3861 - val_sparse_categorical_accuracy: 0.8322\n",
            "Epoch 76/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2852 - sparse_categorical_accuracy: 0.8927 - val_loss: 0.3830 - val_sparse_categorical_accuracy: 0.8405\n",
            "Epoch 77/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2927 - sparse_categorical_accuracy: 0.8826 - val_loss: 0.3842 - val_sparse_categorical_accuracy: 0.8294\n",
            "Epoch 78/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2887 - sparse_categorical_accuracy: 0.8875 - val_loss: 0.3820 - val_sparse_categorical_accuracy: 0.8350\n",
            "Epoch 79/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2990 - sparse_categorical_accuracy: 0.8760 - val_loss: 0.3806 - val_sparse_categorical_accuracy: 0.8294\n",
            "Epoch 80/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2912 - sparse_categorical_accuracy: 0.8806 - val_loss: 0.3794 - val_sparse_categorical_accuracy: 0.8377\n",
            "Epoch 81/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2910 - sparse_categorical_accuracy: 0.8799 - val_loss: 0.3764 - val_sparse_categorical_accuracy: 0.8433\n",
            "Epoch 82/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2741 - sparse_categorical_accuracy: 0.8896 - val_loss: 0.3758 - val_sparse_categorical_accuracy: 0.8419\n",
            "Epoch 83/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2840 - sparse_categorical_accuracy: 0.8861 - val_loss: 0.3759 - val_sparse_categorical_accuracy: 0.8391\n",
            "Epoch 84/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2724 - sparse_categorical_accuracy: 0.8962 - val_loss: 0.3749 - val_sparse_categorical_accuracy: 0.8391\n",
            "Epoch 85/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2738 - sparse_categorical_accuracy: 0.8896 - val_loss: 0.3725 - val_sparse_categorical_accuracy: 0.8447\n",
            "Epoch 86/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2749 - sparse_categorical_accuracy: 0.8917 - val_loss: 0.3721 - val_sparse_categorical_accuracy: 0.8405\n",
            "Epoch 87/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2758 - sparse_categorical_accuracy: 0.8899 - val_loss: 0.3759 - val_sparse_categorical_accuracy: 0.8419\n",
            "Epoch 88/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2636 - sparse_categorical_accuracy: 0.8983 - val_loss: 0.3715 - val_sparse_categorical_accuracy: 0.8433\n",
            "Epoch 89/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2677 - sparse_categorical_accuracy: 0.8955 - val_loss: 0.3740 - val_sparse_categorical_accuracy: 0.8433\n",
            "Epoch 90/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2686 - sparse_categorical_accuracy: 0.8951 - val_loss: 0.3723 - val_sparse_categorical_accuracy: 0.8391\n",
            "Epoch 91/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2698 - sparse_categorical_accuracy: 0.9014 - val_loss: 0.3714 - val_sparse_categorical_accuracy: 0.8377\n",
            "Epoch 92/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2555 - sparse_categorical_accuracy: 0.9045 - val_loss: 0.3692 - val_sparse_categorical_accuracy: 0.8419\n",
            "Epoch 93/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2501 - sparse_categorical_accuracy: 0.9069 - val_loss: 0.3673 - val_sparse_categorical_accuracy: 0.8488\n",
            "Epoch 94/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2627 - sparse_categorical_accuracy: 0.8986 - val_loss: 0.3667 - val_sparse_categorical_accuracy: 0.8460\n",
            "Epoch 95/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2657 - sparse_categorical_accuracy: 0.8979 - val_loss: 0.3666 - val_sparse_categorical_accuracy: 0.8419\n",
            "Epoch 96/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2543 - sparse_categorical_accuracy: 0.9024 - val_loss: 0.3673 - val_sparse_categorical_accuracy: 0.8447\n",
            "Epoch 97/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2636 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.3660 - val_sparse_categorical_accuracy: 0.8474\n",
            "Epoch 98/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2643 - sparse_categorical_accuracy: 0.8986 - val_loss: 0.3636 - val_sparse_categorical_accuracy: 0.8474\n",
            "Epoch 99/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2563 - sparse_categorical_accuracy: 0.8951 - val_loss: 0.3620 - val_sparse_categorical_accuracy: 0.8488\n",
            "Epoch 100/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2561 - sparse_categorical_accuracy: 0.8910 - val_loss: 0.3602 - val_sparse_categorical_accuracy: 0.8516\n",
            "Epoch 101/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2535 - sparse_categorical_accuracy: 0.9045 - val_loss: 0.3587 - val_sparse_categorical_accuracy: 0.8516\n",
            "Epoch 102/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2561 - sparse_categorical_accuracy: 0.8990 - val_loss: 0.3608 - val_sparse_categorical_accuracy: 0.8530\n",
            "Epoch 103/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2519 - sparse_categorical_accuracy: 0.9132 - val_loss: 0.3603 - val_sparse_categorical_accuracy: 0.8488\n",
            "Epoch 104/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2536 - sparse_categorical_accuracy: 0.9031 - val_loss: 0.3562 - val_sparse_categorical_accuracy: 0.8571\n",
            "Epoch 105/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2500 - sparse_categorical_accuracy: 0.9024 - val_loss: 0.3570 - val_sparse_categorical_accuracy: 0.8585\n",
            "Epoch 106/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2451 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.3551 - val_sparse_categorical_accuracy: 0.8599\n",
            "Epoch 107/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2460 - sparse_categorical_accuracy: 0.9104 - val_loss: 0.3528 - val_sparse_categorical_accuracy: 0.8599\n",
            "Epoch 108/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2374 - sparse_categorical_accuracy: 0.9066 - val_loss: 0.3563 - val_sparse_categorical_accuracy: 0.8516\n",
            "Epoch 109/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2430 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.3527 - val_sparse_categorical_accuracy: 0.8558\n",
            "Epoch 110/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2385 - sparse_categorical_accuracy: 0.9073 - val_loss: 0.3532 - val_sparse_categorical_accuracy: 0.8558\n",
            "Epoch 111/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2461 - sparse_categorical_accuracy: 0.9017 - val_loss: 0.3527 - val_sparse_categorical_accuracy: 0.8571\n",
            "Epoch 112/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2386 - sparse_categorical_accuracy: 0.9094 - val_loss: 0.3514 - val_sparse_categorical_accuracy: 0.8599\n",
            "Epoch 113/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2365 - sparse_categorical_accuracy: 0.9139 - val_loss: 0.3531 - val_sparse_categorical_accuracy: 0.8516\n",
            "Epoch 114/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2321 - sparse_categorical_accuracy: 0.9104 - val_loss: 0.3505 - val_sparse_categorical_accuracy: 0.8530\n",
            "Epoch 115/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2243 - sparse_categorical_accuracy: 0.9194 - val_loss: 0.3493 - val_sparse_categorical_accuracy: 0.8585\n",
            "Epoch 116/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2236 - sparse_categorical_accuracy: 0.9194 - val_loss: 0.3505 - val_sparse_categorical_accuracy: 0.8571\n",
            "Epoch 117/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2367 - sparse_categorical_accuracy: 0.9146 - val_loss: 0.3506 - val_sparse_categorical_accuracy: 0.8502\n",
            "Epoch 118/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2300 - sparse_categorical_accuracy: 0.9073 - val_loss: 0.3505 - val_sparse_categorical_accuracy: 0.8585\n",
            "Epoch 119/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2345 - sparse_categorical_accuracy: 0.9094 - val_loss: 0.3506 - val_sparse_categorical_accuracy: 0.8544\n",
            "Epoch 120/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2249 - sparse_categorical_accuracy: 0.9184 - val_loss: 0.3501 - val_sparse_categorical_accuracy: 0.8544\n",
            "Epoch 121/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2219 - sparse_categorical_accuracy: 0.9174 - val_loss: 0.3472 - val_sparse_categorical_accuracy: 0.8585\n",
            "Epoch 122/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2204 - sparse_categorical_accuracy: 0.9153 - val_loss: 0.3496 - val_sparse_categorical_accuracy: 0.8502\n",
            "Epoch 123/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2176 - sparse_categorical_accuracy: 0.9201 - val_loss: 0.3475 - val_sparse_categorical_accuracy: 0.8530\n",
            "Epoch 124/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2192 - sparse_categorical_accuracy: 0.9267 - val_loss: 0.3464 - val_sparse_categorical_accuracy: 0.8558\n",
            "Epoch 125/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2215 - sparse_categorical_accuracy: 0.9181 - val_loss: 0.3485 - val_sparse_categorical_accuracy: 0.8585\n",
            "Epoch 126/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2119 - sparse_categorical_accuracy: 0.9205 - val_loss: 0.3468 - val_sparse_categorical_accuracy: 0.8613\n",
            "Epoch 127/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2143 - sparse_categorical_accuracy: 0.9163 - val_loss: 0.3454 - val_sparse_categorical_accuracy: 0.8627\n",
            "Epoch 128/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2143 - sparse_categorical_accuracy: 0.9205 - val_loss: 0.3440 - val_sparse_categorical_accuracy: 0.8655\n",
            "Epoch 129/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2097 - sparse_categorical_accuracy: 0.9219 - val_loss: 0.3451 - val_sparse_categorical_accuracy: 0.8613\n",
            "Epoch 130/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2106 - sparse_categorical_accuracy: 0.9153 - val_loss: 0.3446 - val_sparse_categorical_accuracy: 0.8641\n",
            "Epoch 131/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2045 - sparse_categorical_accuracy: 0.9212 - val_loss: 0.3433 - val_sparse_categorical_accuracy: 0.8585\n",
            "Epoch 132/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2135 - sparse_categorical_accuracy: 0.9208 - val_loss: 0.3419 - val_sparse_categorical_accuracy: 0.8613\n",
            "Epoch 133/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2101 - sparse_categorical_accuracy: 0.9167 - val_loss: 0.3429 - val_sparse_categorical_accuracy: 0.8655\n",
            "Epoch 134/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2105 - sparse_categorical_accuracy: 0.9243 - val_loss: 0.3463 - val_sparse_categorical_accuracy: 0.8613\n",
            "Epoch 135/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2093 - sparse_categorical_accuracy: 0.9187 - val_loss: 0.3429 - val_sparse_categorical_accuracy: 0.8613\n",
            "Epoch 136/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2124 - sparse_categorical_accuracy: 0.9194 - val_loss: 0.3427 - val_sparse_categorical_accuracy: 0.8669\n",
            "Epoch 137/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2006 - sparse_categorical_accuracy: 0.9247 - val_loss: 0.3423 - val_sparse_categorical_accuracy: 0.8571\n",
            "Epoch 138/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2025 - sparse_categorical_accuracy: 0.9233 - val_loss: 0.3410 - val_sparse_categorical_accuracy: 0.8613\n",
            "Epoch 139/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2029 - sparse_categorical_accuracy: 0.9267 - val_loss: 0.3395 - val_sparse_categorical_accuracy: 0.8558\n",
            "Epoch 140/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2036 - sparse_categorical_accuracy: 0.9236 - val_loss: 0.3391 - val_sparse_categorical_accuracy: 0.8613\n",
            "Epoch 141/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2051 - sparse_categorical_accuracy: 0.9257 - val_loss: 0.3371 - val_sparse_categorical_accuracy: 0.8627\n",
            "Epoch 142/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.1967 - sparse_categorical_accuracy: 0.9233 - val_loss: 0.3394 - val_sparse_categorical_accuracy: 0.8571\n",
            "Epoch 143/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.1998 - sparse_categorical_accuracy: 0.9281 - val_loss: 0.3373 - val_sparse_categorical_accuracy: 0.8571\n",
            "Epoch 144/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.1954 - sparse_categorical_accuracy: 0.9299 - val_loss: 0.3397 - val_sparse_categorical_accuracy: 0.8613\n",
            "Epoch 145/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.1975 - sparse_categorical_accuracy: 0.9278 - val_loss: 0.3355 - val_sparse_categorical_accuracy: 0.8641\n",
            "Epoch 146/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2023 - sparse_categorical_accuracy: 0.9243 - val_loss: 0.3384 - val_sparse_categorical_accuracy: 0.8599\n",
            "Epoch 147/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.1862 - sparse_categorical_accuracy: 0.9361 - val_loss: 0.3368 - val_sparse_categorical_accuracy: 0.8627\n",
            "Epoch 148/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.1989 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.3362 - val_sparse_categorical_accuracy: 0.8613\n",
            "Epoch 149/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2082 - sparse_categorical_accuracy: 0.9219 - val_loss: 0.3344 - val_sparse_categorical_accuracy: 0.8585\n",
            "Epoch 150/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.2028 - sparse_categorical_accuracy: 0.9264 - val_loss: 0.3302 - val_sparse_categorical_accuracy: 0.8627\n",
            "Epoch 151/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.1977 - sparse_categorical_accuracy: 0.9253 - val_loss: 0.3321 - val_sparse_categorical_accuracy: 0.8682\n",
            "Epoch 152/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.1955 - sparse_categorical_accuracy: 0.9257 - val_loss: 0.3352 - val_sparse_categorical_accuracy: 0.8682\n",
            "Epoch 153/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.1862 - sparse_categorical_accuracy: 0.9358 - val_loss: 0.3337 - val_sparse_categorical_accuracy: 0.8641\n",
            "Epoch 154/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.1930 - sparse_categorical_accuracy: 0.9295 - val_loss: 0.3314 - val_sparse_categorical_accuracy: 0.8613\n",
            "Epoch 155/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.1883 - sparse_categorical_accuracy: 0.9278 - val_loss: 0.3310 - val_sparse_categorical_accuracy: 0.8696\n",
            "Epoch 156/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.1941 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.3311 - val_sparse_categorical_accuracy: 0.8599\n",
            "Epoch 157/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.1892 - sparse_categorical_accuracy: 0.9274 - val_loss: 0.3323 - val_sparse_categorical_accuracy: 0.8669\n",
            "Epoch 158/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.1963 - sparse_categorical_accuracy: 0.9299 - val_loss: 0.3287 - val_sparse_categorical_accuracy: 0.8655\n",
            "Epoch 159/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.1849 - sparse_categorical_accuracy: 0.9368 - val_loss: 0.3285 - val_sparse_categorical_accuracy: 0.8627\n",
            "Epoch 160/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.1838 - sparse_categorical_accuracy: 0.9347 - val_loss: 0.3314 - val_sparse_categorical_accuracy: 0.8682\n",
            "Epoch 161/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.1795 - sparse_categorical_accuracy: 0.9406 - val_loss: 0.3309 - val_sparse_categorical_accuracy: 0.8627\n",
            "Epoch 162/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.1905 - sparse_categorical_accuracy: 0.9233 - val_loss: 0.3304 - val_sparse_categorical_accuracy: 0.8613\n",
            "Epoch 163/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.1814 - sparse_categorical_accuracy: 0.9347 - val_loss: 0.3317 - val_sparse_categorical_accuracy: 0.8669\n",
            "Epoch 164/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.1911 - sparse_categorical_accuracy: 0.9267 - val_loss: 0.3322 - val_sparse_categorical_accuracy: 0.8655\n",
            "Epoch 165/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.1833 - sparse_categorical_accuracy: 0.9375 - val_loss: 0.3315 - val_sparse_categorical_accuracy: 0.8627\n",
            "Epoch 166/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.1746 - sparse_categorical_accuracy: 0.9354 - val_loss: 0.3311 - val_sparse_categorical_accuracy: 0.8655\n",
            "Epoch 167/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.1741 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.3329 - val_sparse_categorical_accuracy: 0.8558\n",
            "Epoch 168/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.1830 - sparse_categorical_accuracy: 0.9292 - val_loss: 0.3305 - val_sparse_categorical_accuracy: 0.8599\n",
            "Epoch 169/200\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.1826 - sparse_categorical_accuracy: 0.9285 - val_loss: 0.3295 - val_sparse_categorical_accuracy: 0.8613\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f73dc0ef250>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62zvi7Le75VO",
        "outputId": "57ddea9c-040e-4864-b187-c4ca547f3beb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(model.history.history['loss'])\n",
        "plt.plot(model.history.history['val_loss'])\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfVSBGARrlWI"
      },
      "source": [
        "# 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t32GuCFvrlwv",
        "outputId": "1fd244ab-f70c-40f6-bb07-3c0bdd9ba93f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.evaluate(x_test, y_test, verbose=1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42/42 [==============================] - 3s 80ms/step - loss: 0.3337 - sparse_categorical_accuracy: 0.8424\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.33368781208992004, 0.842424213886261]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-QrQcD_8DjM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}